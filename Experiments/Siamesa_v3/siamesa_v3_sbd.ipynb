{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"siamesa_v3_sbd(3).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8JsIMMmXgvdS","colab_type":"text"},"source":["GENERAL IMPORTS AND SEED"]},{"cell_type":"code","metadata":{"id":"nwQ4Nmxgcmri","colab_type":"code","colab":{}},"source":["import argparse\n","import torch\n","import torchvision\n","from torch import optim\n","from torchvision import transforms\n","import os\n","import os.path as osp\n","import random\n","import numpy as np\n","from pathlib import Path\n","from torch.utils.data import dataset\n","import PIL\n","from PIL import Image\n","\n","# fix the seed\n","seed = 1\n","\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","np.random.seed(seed)\n","random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EAo5WN-79ds","colab_type":"text"},"source":["ACCESS TO THE DRIVE FOLDER WHERE THE DATASET HAS BEEN STORED"]},{"cell_type":"code","metadata":{"id":"HLucYq9Loxgb","colab_type":"code","outputId":"bf85cf85-117b-4216-a4ab-cc055f8dd8cf","executionInfo":{"status":"ok","timestamp":1562098339604,"user_tz":-120,"elapsed":665,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/'  #change dir to your project folder"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wHn2r5ERptEg","colab_type":"text"},"source":["DEFINE ARGUMENTS"]},{"cell_type":"code","metadata":{"id":"qdqM3jDv9VTI","colab_type":"code","colab":{}},"source":["class Args:\n","\n","    frontal_images_directories = \"gdrive/My Drive/dataset-cfp/Protocol/image_list_F.txt\"\n","    profile_images_directories = \"gdrive/My Drive/dataset-cfp/Protocol/image_list_P.txt\"\n","    split_main_directory = \"gdrive/My Drive/dataset-cfp/Protocol/Split\"\n","    split_traindata = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\n","    split_valdata = [\"07\", \"08\"]\n","    split_testdata = [\"09\", \"10\"]\n","    dataset_root = \"gdrive/My Drive\"\n","    dataset= \"CFPDataset\"\n","    lr = float(1e-3)\n","    weight_decay = float(0.0005)\n","    momentum = float(0.9)\n","    betas = (0.9, 0.999)\n","    batch_size = int(14)\n","    workers = int(8)\n","    start_epoch = int(0)\n","    epochs = int(40)\n","    #save_every = int(2)\n","    pretrained = True\n","    #siamese_linear = True\n","    data_aug = True\n","    resume = \"checkpoint_e23_lr1e_3_40e_SGD\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHNIGrMcpw6C","colab_type":"text"},"source":["DEFINE DATASET CLASS"]},{"cell_type":"code","metadata":{"id":"b_gAtqmHsofp","colab_type":"code","colab":{}},"source":["\n","class CFPDataset(dataset.Dataset):\n","    def __init__(self, path, args, img_transforms=None, dataset_root=\"\",\n","                 split=\"train\", input_size=(224, 224)):\n","        super().__init__()\n","\n","        self.data = []\n","        self.split = split\n","\n","        self.load(path, args)\n","\n","        print(\"Dataset loaded\")\n","        print(\"{0} samples in the {1} dataset\".format(len(self.data),\n","                                                      self.split))\n","        self.transforms = img_transforms\n","        self.dataset_root = dataset_root\n","        self.input_size = input_size\n","\n","    def load(self, path, args):\n","\n","        # read directories for frontal images\n","        lines = open(args.frontal_images_directories).readlines()\n","        idx = 0\n","        directories_frontal_images = []\n","        #print(len(lines))\n","        while idx < len(lines):\n","            x = lines[idx].strip().split()\n","            directories_frontal_images.append(x)\n","            idx += 1\n","        #print(x)\n","        # read directories for profile images\n","        lines = open(args.profile_images_directories).readlines()\n","        idx = 0\n","        directories_profile_images = []\n","        #print(len(lines))\n","        while idx < len(lines):\n","            x = lines[idx].strip().split()\n","            directories_profile_images.append(x)\n","            idx += 1\n","        #print(x)\n","        # read same and different pairs of images and save at dictionary\n","        self.data = []\n","        for i in path:\n","            ff_diff_file = osp.join(args.split_main_directory, 'FF', i,\n","                                    'diff.txt')\n","            lines = open(ff_diff_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_diff', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_frontal_images[int(img_pair[1])-1][1]\n","                pair_tag = -1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            ff_same_file = osp.join(args.split_main_directory, 'FF', i,\n","                                    'same.txt')\n","            lines = open(ff_same_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_same', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_frontal_images[int(img_pair[1])-1][1]\n","                pair_tag = 1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            fp_diff_file = osp.join(args.split_main_directory, 'FP', i,\n","                                    'diff.txt')\n","            lines = open(fp_diff_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('fp_diff', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_profile_images[int(img_pair[1])-1][1]\n","                pair_tag = -1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            fp_same_file = osp.join(args.split_main_directory, 'FP', i,\n","                                    'same.txt')\n","            lines = open(fp_same_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_same', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_profile_images[int(img_pair[1])-1][1]\n","                pair_tag = 1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        d = self.data[index]\n","        image1_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n","            'img1_path'])\n","        image2_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n","            'img2_path'])\n","        image1 = Image.open(image1_path).convert('RGB')\n","        image2 = Image.open(image2_path).convert('RGB')\n","        tag = d['pair_tag']\n","        if self.transforms is not None:\n","            # this converts from (HxWxC) to (CxHxW) as wel\n","            img1 = self.transforms(image1)\n","            img2 = self. transforms(image2)\n","\n","        return img1, img2, tag"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNH4HdfMg4Ad","colab_type":"text"},"source":["DEFINE DATA LOADES"]},{"cell_type":"code","metadata":{"id":"OYIFlDuZpiAR","colab_type":"code","colab":{}},"source":["from torch.utils import data\n","\n","def get_dataloader(datapath, args, img_transforms=None, split=\"train\"):\n","\n","    if split == 'train':\n","        shuffle = True\n","        drop_last = True\n","    else:\n","        shuffle = False\n","        drop_last = False\n","    \n","    dataset = CFPDataset(datapath,\n","                         args,\n","                         split=split,\n","                         img_transforms=img_transforms,\n","                         dataset_root=osp.expanduser(args.dataset_root))\n","    \n","    data_loader = data.DataLoader(dataset,\n","                                  batch_size=args.batch_size,\n","                                  shuffle=shuffle,    \n","                                  num_workers=args.workers,\n","                                  pin_memory=True,\n","                                  drop_last=drop_last)\n","    return data_loader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOTmj-LtqZnX","colab_type":"text"},"source":["DEFINE MODEL"]},{"cell_type":"code","metadata":{"id":"OboRfyRMqbP8","colab_type":"code","colab":{}},"source":["\n","import torch\n","from torch import nn\n","from torchvision.models import vgg16_bn\n","\n","def l2norm(x):\n","  x = x / torch.sqrt(torch.sum(x**2, dim=-1, keepdim=True))\n","  return x\n","\n","class SiameseCosine(nn.Module):\n","    \"\"\"\n","    Siamese network\n","    \"\"\"\n","    def __init__(self, pretrained=False):\n","        super(SiameseCosine, self).__init__()\n","\n","        vgg16_model = vgg16_bn(pretrained=pretrained)\n","        self.feat = vgg16_model.features\n","        self.linear_classifier = vgg16_model.classifier[0]\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n","\n","    def forward(self, img1, img2):\n","        feat_1 = self.feat(img1)\n","        feat_1 = self. avgpool(feat_1)\n","        feat_1 = feat_1.view(feat_1.size(0),-1)\n","        feat_1 = self.linear_classifier(feat_1)\n","        feat_1 = l2norm(feat_1)\n","        \n","        feat_2 = self.feat(img2)\n","        feat_2 = self. avgpool(feat_2)\n","        feat_2 = feat_2.view(feat_1.size(0),-1)\n","        feat_2 = self.linear_classifier(feat_2)\n","        feat_2 = l2norm(feat_2)\n","\n","      \n","        return feat_1, feat_2\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I7A5_ZZdqf8Z","colab_type":"text"},"source":["DEFINE LOSS"]},{"cell_type":"code","metadata":{"id":"VLLRaLvFqit5","colab_type":"code","colab":{}},"source":["from torch import nn\n","\n","class RecognitionCriterion(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.classification_criterion = nn.CosineEmbeddingLoss(margin=0.5).cuda()\n","        self.cls_loss = None\n","\n","    def forward(self, *input):\n","        self.cls_loss = self.classification_criterion(*input)\n","        return self.cls_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8c_WD2OCqnYa","colab_type":"text"},"source":["DEFINE TRAINING AND VALIDATION FUNCTIONS"]},{"cell_type":"code","metadata":{"id":"8c-eqydZqtKz","colab_type":"code","colab":{}},"source":["import torch\n","from torchvision import transforms\n","from torch.nn import functional as nnfunc\n","import numpy as np\n","\n","def similarity (vec1, vec2):\n","    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-8)\n","    cos_a = cos (vec1, vec2)  \n","    return cos_a\n","  \n","def accuracy(vec1, vec2, y, treshold):\n","    correct = 0\n","    total = 0\n","\n","    similarity_value = similarity(vec1, vec2)\n","   \n","    for value, label in zip(similarity_value, y):\n","        total += 1\n","        if value > treshold and label == 1.0:\n","            correct += 1\n","        if value < treshold and label == -1.0:\n","            correct += 1\n","    return correct/total\n","\n","def train(model, loss_fn, optimizer, dataloader, epoch, device):\n","    model.train()\n","    all_loss = []\n","        \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","     \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","   \n","        loss = loss_fn(out1, out2, prob) #calculates loss\n","        loss.backward() #upgrades gradients\n","        all_loss.append(loss.item())\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if idx % 100 == 0:\n","            message1 = \"TRAIN Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            #message2 = \"Loss: [{0:.4f}]; Accuracy: [{1}]\".format(loss.item(),\n","            #                                                    acc)\n","            message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_loss\n","\n","def val(model, loss_fn, dataloader, epoch, device):\n","    model.eval()\n","    all_loss = []\n","    \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","   \n","        loss = loss_fn(out1, out2, prob) #calculates loss\n","        all_loss.append(loss.item())\n","                  \n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            #message2 = \"Loss: [{0:.4f}]; Accuracy: [{1:.4f}]\".format(loss.item(),\n","            #                                                    acc)\n","            message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_loss\n","  \n","def val_sim_lim(model, dataloader, epoch, device):\n","    model.eval()\n","\n","    sim_pos_min = 1\n","    sim_neg_max = -1\n","    pos_similarities = []\n","    neg_similarities = []\n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","             \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","        \n","        sim = similarity(out1, out2)\n","        for value, label in zip(sim, prob):\n","            value = value.item()\n","            np.round(value, decimals=3)\n","            if label == 1:\n","                pos_similarities.append(value)\n","            else:\n","                neg_similarities.append(value)     \n","                \n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            print(message1)\n","        torch.cuda.empty_cache()\n","    return pos_similarities, neg_similarities\n","  \n","def val_tr(model, dataloader, epoch, device, tr):\n","    model.eval()\n","    all_loss = []\n","    all_acc = []  \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","           \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","\n","        acc = accuracy(out1, out2, prob, tr)\n","        all_acc.append(acc)\n","\n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            message2 = \"Accuracy: [{0}]\".format(acc)\n","            #message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_acc\n","  \n","  \n","def test(model, loss_fn, dataloader, epoch, device, tr):\n","    #model = model.to(device)\n","    model.eval()\n","    all_acc = []\n","        \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","     \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","\n","        acc = accuracy(out1, out2, prob, tr)\n","        all_acc.append(acc)\n","\n","        if idx % 100 == 0:\n","            message1 = \"TEST Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            message2 = \"Accuracy: [{0}]\".format(acc)\n","            #message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AVw1szFKg-jn","colab_type":"text"},"source":["LOAD ARGUMENTS AND DEFINE IMAGE TRANSFORMATIONS"]},{"cell_type":"code","metadata":{"id":"8iZoeeWM9umb","colab_type":"code","colab":{}},"source":["args = Args()\n","\n","train_transform=None\n","if args.data_aug == False:\n","  img_transforms = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n","\n","else:\n","  img_transforms = transforms.Compose([transforms.Resize((224, 224)), \n","                                        transforms.RandomHorizontalFlip(), \n","                                        transforms.RandomRotation(20, resample=PIL.Image.BILINEAR), \n","                                        transforms.ToTensor()])\n","\n","    \n","\n","val_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HlXDRuy5hCyu","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR TRAINING"]},{"cell_type":"code","metadata":{"id":"yGzZEm6j94ML","colab_type":"code","outputId":"f124b870-f29f-490e-e5cc-f3cfc08b7b86","executionInfo":{"status":"ok","timestamp":1562067048824,"user_tz":-120,"elapsed":11311,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["train_loader = get_dataloader(args.split_traindata, args,\n","                              img_transforms=img_transforms)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","8400 samples in the train dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RJeIo10phGTV","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR VALIDATION"]},{"cell_type":"code","metadata":{"id":"FKQgt_NDrA5L","colab_type":"code","outputId":"28d11974-0894-4976-9424-cbbb02e8013b","executionInfo":{"status":"ok","timestamp":1562098363041,"user_tz":-120,"elapsed":652,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["val_loader = get_dataloader(args.split_valdata, args,\n","                            img_transforms=val_transforms, split=\"val\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","2800 samples in the val dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NJU0i3PpLAHm","colab_type":"code","outputId":"43f84596-c40f-4a2d-f9ad-25b04b290c3c","executionInfo":{"status":"ok","timestamp":1562098370559,"user_tz":-120,"elapsed":756,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.cuda.is_available()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"MHt6d-CWhNio","colab_type":"text"},"source":["SPECIFY DEVICE"]},{"cell_type":"code","metadata":{"id":"X8NbSOen-wOy","colab_type":"code","colab":{}},"source":["# check for CUDA\n","if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cx8uckQUhPUM","colab_type":"text"},"source":["LOAD MODEL AND LOSS "]},{"cell_type":"code","metadata":{"id":"_cTc5vSct0U4","colab_type":"code","colab":{}},"source":["\n","model = SiameseCosine(pretrained=args.pretrained)\n","\n","model = model.to(device) # treure de train i validation\n","\n","loss_fn = RecognitionCriterion()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqtb__47hSSi","colab_type":"text"},"source":["SPECIFY WHEIGHTS DIRECTORY"]},{"cell_type":"code","metadata":{"id":"ZFg3godAt06I","colab_type":"code","colab":{}},"source":["# directory where we'll store model weights\n","weights_dir = \"gdrive/My Drive/weights\"\n","if not osp.exists(weights_dir):\n","    os.mkdir(weights_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6guiGa6ihV-H","colab_type":"text"},"source":["SELECT OPTIMIZER"]},{"cell_type":"code","metadata":{"id":"kRW8oa-H-3gT","colab_type":"code","colab":{}},"source":["#optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,\n","#                             weight_decay=args.weight_decay)\n","\n","optimizer = optim.SGD(model.parameters(), lr=args.lr,\n","                      momentum=args.momentum, weight_decay=args.weight_decay)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHG-yrsEhYAV","colab_type":"text"},"source":["DEFINE CHECKPOINT"]},{"cell_type":"code","metadata":{"id":"WAS5FOei-8T1","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, filename=\"checkpoint.pth\", save_path=weights_dir):\n","    # check if the save directory exists\n","    if not Path(save_path).exists():\n","        Path(save_path).mkdir()\n","\n","    save_path = Path(save_path, filename)\n","    torch.save(state, str(save_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0f7Oiz8haCx","colab_type":"text"},"source":["RUN TRAIN"]},{"cell_type":"code","metadata":{"id":"E0ddySP2_DPR","colab_type":"code","outputId":"63c1c52d-5f1e-45b8-ff7b-9b6b3297f3ec","executionInfo":{"status":"ok","timestamp":1562091151083,"user_tz":-120,"elapsed":24045576,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","# train and evalute for `epochs`\n","loss_epoch_train = []\n","loss_epoch_val = []\n","acc_epoch_train = []\n","acc_epoch_val = []\n","\n","best_loss = 100\n","best_epoch = 0\n","\n","for epoch in range(args.start_epoch, args.epochs):\n","    # scheduler.step()\n","    train_loss = train(model, loss_fn, optimizer, train_loader, epoch, device=device)\n","    \n","    av_loss = np.mean(train_loss)\n","    loss_epoch_train.append(av_loss)\n","\n","\n","    val_loss = val(model, loss_fn, val_loader, epoch, device=device)\n","    \n","    av_loss = np.mean(val_loss)\n","    loss_epoch_val.append(av_loss)\n","\n","    if best_loss > av_loss:\n","        best_loss = av_loss\n","        best_epoch = epoch\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'batch_size': val_loader.batch_size,\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","         }, filename=str(args.resume)+\".pth\",\n","             save_path=weights_dir)\n","    \n","print(\"Best Epoch: \",best_epoch, \"Best Loss: \", best_loss)\n","    \n","epochs = range(1, len(loss_epoch_train) + 1)\n","# b is for \"solid blue line\"\n","plt.plot(epochs, loss_epoch_train, 'b', label='Training loss')\n","# r is for \"solid red line\"\n","plt.plot(epochs, loss_epoch_val, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","#epochs = range(1, len(acc_epoch_train) + 1)\n","# b is for \"solid blue line\"\n","#plt.plot(epochs, acc_epoch_train, 'b', label='Training accuracy')\n","# r is for \"solid red line\"\n","#plt.plot(epochs, acc_epoch_val, 'r', label='Validation accuracy')\n","#plt.title('Training and validation accuracy')\n","#plt.xlabel('Epochs')\n","#plt.ylabel('Accuracy')\n","#plt.legend()\n","#plt.show()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["TRAIN Epoch [0]: [0/600]  Loss: [0.1080]\n","TRAIN Epoch [0]: [100/600]  Loss: [0.1172]\n","TRAIN Epoch [0]: [200/600]  Loss: [0.2114]\n","TRAIN Epoch [0]: [300/600]  Loss: [0.2063]\n","TRAIN Epoch [0]: [400/600]  Loss: [0.2105]\n","TRAIN Epoch [0]: [500/600]  Loss: [0.2178]\n","VAL Epoch [0]: [0/200]  Loss: [0.1021]\n","VAL Epoch [0]: [100/200]  Loss: [0.0672]\n","TRAIN Epoch [1]: [0/600]  Loss: [0.2227]\n","TRAIN Epoch [1]: [100/600]  Loss: [0.1890]\n","TRAIN Epoch [1]: [200/600]  Loss: [0.1801]\n","TRAIN Epoch [1]: [300/600]  Loss: [0.1705]\n","TRAIN Epoch [1]: [400/600]  Loss: [0.1183]\n","TRAIN Epoch [1]: [500/600]  Loss: [0.2071]\n","VAL Epoch [1]: [0/200]  Loss: [0.1376]\n","VAL Epoch [1]: [100/200]  Loss: [0.0603]\n","TRAIN Epoch [2]: [0/600]  Loss: [0.1619]\n","TRAIN Epoch [2]: [100/600]  Loss: [0.2246]\n","TRAIN Epoch [2]: [200/600]  Loss: [0.2350]\n","TRAIN Epoch [2]: [300/600]  Loss: [0.1982]\n","TRAIN Epoch [2]: [400/600]  Loss: [0.1776]\n","TRAIN Epoch [2]: [500/600]  Loss: [0.1553]\n","VAL Epoch [2]: [0/200]  Loss: [0.1658]\n","VAL Epoch [2]: [100/200]  Loss: [0.0575]\n","TRAIN Epoch [3]: [0/600]  Loss: [0.1390]\n","TRAIN Epoch [3]: [100/600]  Loss: [0.2018]\n","TRAIN Epoch [3]: [200/600]  Loss: [0.1600]\n","TRAIN Epoch [3]: [300/600]  Loss: [0.0857]\n","TRAIN Epoch [3]: [400/600]  Loss: [0.1550]\n","TRAIN Epoch [3]: [500/600]  Loss: [0.1412]\n","VAL Epoch [3]: [0/200]  Loss: [0.1716]\n","VAL Epoch [3]: [100/200]  Loss: [0.0648]\n","TRAIN Epoch [4]: [0/600]  Loss: [0.1496]\n","TRAIN Epoch [4]: [100/600]  Loss: [0.1031]\n","TRAIN Epoch [4]: [200/600]  Loss: [0.1194]\n","TRAIN Epoch [4]: [300/600]  Loss: [0.1046]\n","TRAIN Epoch [4]: [400/600]  Loss: [0.1127]\n","TRAIN Epoch [4]: [500/600]  Loss: [0.1216]\n","VAL Epoch [4]: [0/200]  Loss: [0.1805]\n","VAL Epoch [4]: [100/200]  Loss: [0.0665]\n","TRAIN Epoch [5]: [0/600]  Loss: [0.0792]\n","TRAIN Epoch [5]: [100/600]  Loss: [0.1464]\n","TRAIN Epoch [5]: [200/600]  Loss: [0.0892]\n","TRAIN Epoch [5]: [300/600]  Loss: [0.1045]\n","TRAIN Epoch [5]: [400/600]  Loss: [0.1741]\n","TRAIN Epoch [5]: [500/600]  Loss: [0.0976]\n","VAL Epoch [5]: [0/200]  Loss: [0.1767]\n","VAL Epoch [5]: [100/200]  Loss: [0.0650]\n","TRAIN Epoch [6]: [0/600]  Loss: [0.1222]\n","TRAIN Epoch [6]: [100/600]  Loss: [0.1173]\n","TRAIN Epoch [6]: [200/600]  Loss: [0.0695]\n","TRAIN Epoch [6]: [300/600]  Loss: [0.1352]\n","TRAIN Epoch [6]: [400/600]  Loss: [0.0725]\n","TRAIN Epoch [6]: [500/600]  Loss: [0.1326]\n","VAL Epoch [6]: [0/200]  Loss: [0.1910]\n","VAL Epoch [6]: [100/200]  Loss: [0.0563]\n","TRAIN Epoch [7]: [0/600]  Loss: [0.0913]\n","TRAIN Epoch [7]: [100/600]  Loss: [0.1533]\n","TRAIN Epoch [7]: [200/600]  Loss: [0.1380]\n","TRAIN Epoch [7]: [300/600]  Loss: [0.1510]\n","TRAIN Epoch [7]: [400/600]  Loss: [0.1655]\n","TRAIN Epoch [7]: [500/600]  Loss: [0.1792]\n","VAL Epoch [7]: [0/200]  Loss: [0.1928]\n","VAL Epoch [7]: [100/200]  Loss: [0.0540]\n","TRAIN Epoch [8]: [0/600]  Loss: [0.0842]\n","TRAIN Epoch [8]: [100/600]  Loss: [0.0815]\n","TRAIN Epoch [8]: [200/600]  Loss: [0.0863]\n","TRAIN Epoch [8]: [300/600]  Loss: [0.1468]\n","TRAIN Epoch [8]: [400/600]  Loss: [0.1377]\n","TRAIN Epoch [8]: [500/600]  Loss: [0.1844]\n","VAL Epoch [8]: [0/200]  Loss: [0.1989]\n","VAL Epoch [8]: [100/200]  Loss: [0.0599]\n","TRAIN Epoch [9]: [0/600]  Loss: [0.1067]\n","TRAIN Epoch [9]: [100/600]  Loss: [0.0943]\n","TRAIN Epoch [9]: [200/600]  Loss: [0.1090]\n","TRAIN Epoch [9]: [300/600]  Loss: [0.1236]\n","TRAIN Epoch [9]: [400/600]  Loss: [0.1380]\n","TRAIN Epoch [9]: [500/600]  Loss: [0.0926]\n","VAL Epoch [9]: [0/200]  Loss: [0.2002]\n","VAL Epoch [9]: [100/200]  Loss: [0.0534]\n","TRAIN Epoch [10]: [0/600]  Loss: [0.1048]\n","TRAIN Epoch [10]: [100/600]  Loss: [0.1387]\n","TRAIN Epoch [10]: [200/600]  Loss: [0.0861]\n","TRAIN Epoch [10]: [300/600]  Loss: [0.1494]\n","TRAIN Epoch [10]: [400/600]  Loss: [0.0970]\n","TRAIN Epoch [10]: [500/600]  Loss: [0.1105]\n","VAL Epoch [10]: [0/200]  Loss: [0.1978]\n","VAL Epoch [10]: [100/200]  Loss: [0.0530]\n","TRAIN Epoch [11]: [0/600]  Loss: [0.1678]\n","TRAIN Epoch [11]: [100/600]  Loss: [0.0517]\n","TRAIN Epoch [11]: [200/600]  Loss: [0.0889]\n","TRAIN Epoch [11]: [300/600]  Loss: [0.1184]\n","TRAIN Epoch [11]: [400/600]  Loss: [0.0563]\n","TRAIN Epoch [11]: [500/600]  Loss: [0.0887]\n","VAL Epoch [11]: [0/200]  Loss: [0.2000]\n","VAL Epoch [11]: [100/200]  Loss: [0.0513]\n","TRAIN Epoch [12]: [0/600]  Loss: [0.1034]\n","TRAIN Epoch [12]: [100/600]  Loss: [0.1195]\n","TRAIN Epoch [12]: [200/600]  Loss: [0.0435]\n","TRAIN Epoch [12]: [300/600]  Loss: [0.0766]\n","TRAIN Epoch [12]: [400/600]  Loss: [0.0728]\n","TRAIN Epoch [12]: [500/600]  Loss: [0.1355]\n","VAL Epoch [12]: [0/200]  Loss: [0.1936]\n","VAL Epoch [12]: [100/200]  Loss: [0.0508]\n","TRAIN Epoch [13]: [0/600]  Loss: [0.0873]\n","TRAIN Epoch [13]: [100/600]  Loss: [0.0611]\n","TRAIN Epoch [13]: [200/600]  Loss: [0.1784]\n","TRAIN Epoch [13]: [300/600]  Loss: [0.0648]\n","TRAIN Epoch [13]: [400/600]  Loss: [0.0973]\n","TRAIN Epoch [13]: [500/600]  Loss: [0.0638]\n","VAL Epoch [13]: [0/200]  Loss: [0.1963]\n","VAL Epoch [13]: [100/200]  Loss: [0.0484]\n","TRAIN Epoch [14]: [0/600]  Loss: [0.1183]\n","TRAIN Epoch [14]: [100/600]  Loss: [0.0725]\n","TRAIN Epoch [14]: [200/600]  Loss: [0.0861]\n","TRAIN Epoch [14]: [300/600]  Loss: [0.0862]\n","TRAIN Epoch [14]: [400/600]  Loss: [0.0863]\n","TRAIN Epoch [14]: [500/600]  Loss: [0.1047]\n","VAL Epoch [14]: [0/200]  Loss: [0.1999]\n","VAL Epoch [14]: [100/200]  Loss: [0.0432]\n","TRAIN Epoch [15]: [0/600]  Loss: [0.1551]\n","TRAIN Epoch [15]: [100/600]  Loss: [0.0906]\n","TRAIN Epoch [15]: [200/600]  Loss: [0.0483]\n","TRAIN Epoch [15]: [300/600]  Loss: [0.0771]\n","TRAIN Epoch [15]: [400/600]  Loss: [0.0902]\n","TRAIN Epoch [15]: [500/600]  Loss: [0.0372]\n","VAL Epoch [15]: [0/200]  Loss: [0.1999]\n","VAL Epoch [15]: [100/200]  Loss: [0.0408]\n","TRAIN Epoch [16]: [0/600]  Loss: [0.1211]\n","TRAIN Epoch [16]: [100/600]  Loss: [0.1037]\n","TRAIN Epoch [16]: [200/600]  Loss: [0.0667]\n","TRAIN Epoch [16]: [300/600]  Loss: [0.1599]\n","TRAIN Epoch [16]: [400/600]  Loss: [0.0266]\n","TRAIN Epoch [16]: [500/600]  Loss: [0.0484]\n","VAL Epoch [16]: [0/200]  Loss: [0.1868]\n","VAL Epoch [16]: [100/200]  Loss: [0.0421]\n","TRAIN Epoch [17]: [0/600]  Loss: [0.1155]\n","TRAIN Epoch [17]: [100/600]  Loss: [0.1340]\n","TRAIN Epoch [17]: [200/600]  Loss: [0.1036]\n","TRAIN Epoch [17]: [300/600]  Loss: [0.0855]\n","TRAIN Epoch [17]: [400/600]  Loss: [0.0374]\n","TRAIN Epoch [17]: [500/600]  Loss: [0.0546]\n","VAL Epoch [17]: [0/200]  Loss: [0.1859]\n","VAL Epoch [17]: [100/200]  Loss: [0.0413]\n","TRAIN Epoch [18]: [0/600]  Loss: [0.0836]\n","TRAIN Epoch [18]: [100/600]  Loss: [0.0587]\n","TRAIN Epoch [18]: [200/600]  Loss: [0.0810]\n","TRAIN Epoch [18]: [300/600]  Loss: [0.0448]\n","TRAIN Epoch [18]: [400/600]  Loss: [0.0964]\n","TRAIN Epoch [18]: [500/600]  Loss: [0.0511]\n","VAL Epoch [18]: [0/200]  Loss: [0.1893]\n","VAL Epoch [18]: [100/200]  Loss: [0.0354]\n","TRAIN Epoch [19]: [0/600]  Loss: [0.0443]\n","TRAIN Epoch [19]: [100/600]  Loss: [0.0535]\n","TRAIN Epoch [19]: [200/600]  Loss: [0.0960]\n","TRAIN Epoch [19]: [300/600]  Loss: [0.0247]\n","TRAIN Epoch [19]: [400/600]  Loss: [0.0736]\n","TRAIN Epoch [19]: [500/600]  Loss: [0.1098]\n","VAL Epoch [19]: [0/200]  Loss: [0.1886]\n","VAL Epoch [19]: [100/200]  Loss: [0.0380]\n","TRAIN Epoch [20]: [0/600]  Loss: [0.0772]\n","TRAIN Epoch [20]: [100/600]  Loss: [0.1032]\n","TRAIN Epoch [20]: [200/600]  Loss: [0.0459]\n","TRAIN Epoch [20]: [300/600]  Loss: [0.0749]\n","TRAIN Epoch [20]: [400/600]  Loss: [0.0881]\n","TRAIN Epoch [20]: [500/600]  Loss: [0.0948]\n","VAL Epoch [20]: [0/200]  Loss: [0.1870]\n","VAL Epoch [20]: [100/200]  Loss: [0.0333]\n","TRAIN Epoch [21]: [0/600]  Loss: [0.0664]\n","TRAIN Epoch [21]: [100/600]  Loss: [0.0447]\n","TRAIN Epoch [21]: [200/600]  Loss: [0.1013]\n","TRAIN Epoch [21]: [300/600]  Loss: [0.0433]\n","TRAIN Epoch [21]: [400/600]  Loss: [0.0671]\n","TRAIN Epoch [21]: [500/600]  Loss: [0.0419]\n","VAL Epoch [21]: [0/200]  Loss: [0.1847]\n","VAL Epoch [21]: [100/200]  Loss: [0.0400]\n","TRAIN Epoch [22]: [0/600]  Loss: [0.0674]\n","TRAIN Epoch [22]: [100/600]  Loss: [0.0236]\n","TRAIN Epoch [22]: [200/600]  Loss: [0.0406]\n","TRAIN Epoch [22]: [300/600]  Loss: [0.0587]\n","TRAIN Epoch [22]: [400/600]  Loss: [0.0558]\n","TRAIN Epoch [22]: [500/600]  Loss: [0.0364]\n","VAL Epoch [22]: [0/200]  Loss: [0.1755]\n","VAL Epoch [22]: [100/200]  Loss: [0.0380]\n","TRAIN Epoch [23]: [0/600]  Loss: [0.0744]\n","TRAIN Epoch [23]: [100/600]  Loss: [0.0287]\n","TRAIN Epoch [23]: [200/600]  Loss: [0.0912]\n","TRAIN Epoch [23]: [300/600]  Loss: [0.0756]\n","TRAIN Epoch [23]: [400/600]  Loss: [0.0177]\n","TRAIN Epoch [23]: [500/600]  Loss: [0.0233]\n","VAL Epoch [23]: [0/200]  Loss: [0.1887]\n","VAL Epoch [23]: [100/200]  Loss: [0.0375]\n","TRAIN Epoch [24]: [0/600]  Loss: [0.0657]\n","TRAIN Epoch [24]: [100/600]  Loss: [0.0133]\n","TRAIN Epoch [24]: [200/600]  Loss: [0.0445]\n","TRAIN Epoch [24]: [300/600]  Loss: [0.0929]\n","TRAIN Epoch [24]: [400/600]  Loss: [0.0471]\n","TRAIN Epoch [24]: [500/600]  Loss: [0.0817]\n","VAL Epoch [24]: [0/200]  Loss: [0.1893]\n","VAL Epoch [24]: [100/200]  Loss: [0.0372]\n","TRAIN Epoch [25]: [0/600]  Loss: [0.0326]\n","TRAIN Epoch [25]: [100/600]  Loss: [0.0557]\n","TRAIN Epoch [25]: [200/600]  Loss: [0.0420]\n","TRAIN Epoch [25]: [300/600]  Loss: [0.0413]\n","TRAIN Epoch [25]: [400/600]  Loss: [0.0135]\n","TRAIN Epoch [25]: [500/600]  Loss: [0.0518]\n","VAL Epoch [25]: [0/200]  Loss: [0.1824]\n","VAL Epoch [25]: [100/200]  Loss: [0.0341]\n","TRAIN Epoch [26]: [0/600]  Loss: [0.0829]\n","TRAIN Epoch [26]: [100/600]  Loss: [0.0599]\n","TRAIN Epoch [26]: [200/600]  Loss: [0.0900]\n","TRAIN Epoch [26]: [300/600]  Loss: [0.0877]\n","TRAIN Epoch [26]: [400/600]  Loss: [0.0491]\n","TRAIN Epoch [26]: [500/600]  Loss: [0.0499]\n","VAL Epoch [26]: [0/200]  Loss: [0.1803]\n","VAL Epoch [26]: [100/200]  Loss: [0.0344]\n","TRAIN Epoch [27]: [0/600]  Loss: [0.1060]\n","TRAIN Epoch [27]: [100/600]  Loss: [0.0442]\n","TRAIN Epoch [27]: [200/600]  Loss: [0.0620]\n","TRAIN Epoch [27]: [300/600]  Loss: [0.0135]\n","TRAIN Epoch [27]: [400/600]  Loss: [0.1370]\n","TRAIN Epoch [27]: [500/600]  Loss: [0.0726]\n","VAL Epoch [27]: [0/200]  Loss: [0.1813]\n","VAL Epoch [27]: [100/200]  Loss: [0.0338]\n","TRAIN Epoch [28]: [0/600]  Loss: [0.0573]\n","TRAIN Epoch [28]: [100/600]  Loss: [0.0465]\n","TRAIN Epoch [28]: [200/600]  Loss: [0.0872]\n","TRAIN Epoch [28]: [300/600]  Loss: [0.0974]\n","TRAIN Epoch [28]: [400/600]  Loss: [0.1087]\n","TRAIN Epoch [28]: [500/600]  Loss: [0.0451]\n","VAL Epoch [28]: [0/200]  Loss: [0.1909]\n","VAL Epoch [28]: [100/200]  Loss: [0.0338]\n","TRAIN Epoch [29]: [0/600]  Loss: [0.0412]\n","TRAIN Epoch [29]: [100/600]  Loss: [0.0496]\n","TRAIN Epoch [29]: [200/600]  Loss: [0.0626]\n","TRAIN Epoch [29]: [300/600]  Loss: [0.0528]\n","TRAIN Epoch [29]: [400/600]  Loss: [0.0754]\n","TRAIN Epoch [29]: [500/600]  Loss: [0.0422]\n","VAL Epoch [29]: [0/200]  Loss: [0.1870]\n","VAL Epoch [29]: [100/200]  Loss: [0.0343]\n","TRAIN Epoch [30]: [0/600]  Loss: [0.0403]\n","TRAIN Epoch [30]: [100/600]  Loss: [0.0774]\n","TRAIN Epoch [30]: [200/600]  Loss: [0.0762]\n","TRAIN Epoch [30]: [300/600]  Loss: [0.0639]\n","TRAIN Epoch [30]: [400/600]  Loss: [0.0453]\n","TRAIN Epoch [30]: [500/600]  Loss: [0.0311]\n","VAL Epoch [30]: [0/200]  Loss: [0.1813]\n","VAL Epoch [30]: [100/200]  Loss: [0.0340]\n","TRAIN Epoch [31]: [0/600]  Loss: [0.0626]\n","TRAIN Epoch [31]: [100/600]  Loss: [0.0283]\n","TRAIN Epoch [31]: [200/600]  Loss: [0.0645]\n","TRAIN Epoch [31]: [300/600]  Loss: [0.0623]\n","TRAIN Epoch [31]: [400/600]  Loss: [0.0688]\n","TRAIN Epoch [31]: [500/600]  Loss: [0.0216]\n","VAL Epoch [31]: [0/200]  Loss: [0.1824]\n","VAL Epoch [31]: [100/200]  Loss: [0.0336]\n","TRAIN Epoch [32]: [0/600]  Loss: [0.0453]\n","TRAIN Epoch [32]: [100/600]  Loss: [0.0435]\n","TRAIN Epoch [32]: [200/600]  Loss: [0.0720]\n","TRAIN Epoch [32]: [300/600]  Loss: [0.0917]\n","TRAIN Epoch [32]: [400/600]  Loss: [0.0287]\n","TRAIN Epoch [32]: [500/600]  Loss: [0.0343]\n","VAL Epoch [32]: [0/200]  Loss: [0.1786]\n","VAL Epoch [32]: [100/200]  Loss: [0.0331]\n","TRAIN Epoch [33]: [0/600]  Loss: [0.0211]\n","TRAIN Epoch [33]: [100/600]  Loss: [0.0320]\n","TRAIN Epoch [33]: [200/600]  Loss: [0.0646]\n","TRAIN Epoch [33]: [300/600]  Loss: [0.0854]\n","TRAIN Epoch [33]: [400/600]  Loss: [0.0534]\n","TRAIN Epoch [33]: [500/600]  Loss: [0.0254]\n","VAL Epoch [33]: [0/200]  Loss: [0.1806]\n","VAL Epoch [33]: [100/200]  Loss: [0.0324]\n","TRAIN Epoch [34]: [0/600]  Loss: [0.0217]\n","TRAIN Epoch [34]: [100/600]  Loss: [0.0458]\n","TRAIN Epoch [34]: [200/600]  Loss: [0.0475]\n","TRAIN Epoch [34]: [300/600]  Loss: [0.1082]\n","TRAIN Epoch [34]: [400/600]  Loss: [0.0419]\n","TRAIN Epoch [34]: [500/600]  Loss: [0.0620]\n","VAL Epoch [34]: [0/200]  Loss: [0.1824]\n","VAL Epoch [34]: [100/200]  Loss: [0.0335]\n","TRAIN Epoch [35]: [0/600]  Loss: [0.0506]\n","TRAIN Epoch [35]: [100/600]  Loss: [0.0642]\n","TRAIN Epoch [35]: [200/600]  Loss: [0.0616]\n","TRAIN Epoch [35]: [300/600]  Loss: [0.0417]\n","TRAIN Epoch [35]: [400/600]  Loss: [0.0661]\n","TRAIN Epoch [35]: [500/600]  Loss: [0.0433]\n","VAL Epoch [35]: [0/200]  Loss: [0.1773]\n","VAL Epoch [35]: [100/200]  Loss: [0.0332]\n","TRAIN Epoch [36]: [0/600]  Loss: [0.1021]\n","TRAIN Epoch [36]: [100/600]  Loss: [0.0556]\n","TRAIN Epoch [36]: [200/600]  Loss: [0.0849]\n","TRAIN Epoch [36]: [300/600]  Loss: [0.0165]\n","TRAIN Epoch [36]: [400/600]  Loss: [0.0629]\n","TRAIN Epoch [36]: [500/600]  Loss: [0.0211]\n","VAL Epoch [36]: [0/200]  Loss: [0.1728]\n","VAL Epoch [36]: [100/200]  Loss: [0.0343]\n","TRAIN Epoch [37]: [0/600]  Loss: [0.0602]\n","TRAIN Epoch [37]: [100/600]  Loss: [0.0248]\n","TRAIN Epoch [37]: [200/600]  Loss: [0.1107]\n","TRAIN Epoch [37]: [300/600]  Loss: [0.0430]\n","TRAIN Epoch [37]: [400/600]  Loss: [0.0121]\n","TRAIN Epoch [37]: [500/600]  Loss: [0.0385]\n","VAL Epoch [37]: [0/200]  Loss: [0.1886]\n","VAL Epoch [37]: [100/200]  Loss: [0.0383]\n","TRAIN Epoch [38]: [0/600]  Loss: [0.0664]\n","TRAIN Epoch [38]: [100/600]  Loss: [0.0295]\n","TRAIN Epoch [38]: [200/600]  Loss: [0.0134]\n","TRAIN Epoch [38]: [300/600]  Loss: [0.0804]\n","TRAIN Epoch [38]: [400/600]  Loss: [0.0970]\n","TRAIN Epoch [38]: [500/600]  Loss: [0.0405]\n","VAL Epoch [38]: [0/200]  Loss: [0.1787]\n","VAL Epoch [38]: [100/200]  Loss: [0.0356]\n","TRAIN Epoch [39]: [0/600]  Loss: [0.0516]\n","TRAIN Epoch [39]: [100/600]  Loss: [0.0309]\n","TRAIN Epoch [39]: [200/600]  Loss: [0.0969]\n","TRAIN Epoch [39]: [300/600]  Loss: [0.0606]\n","TRAIN Epoch [39]: [400/600]  Loss: [0.0132]\n","TRAIN Epoch [39]: [500/600]  Loss: [0.0098]\n","VAL Epoch [39]: [0/200]  Loss: [0.1835]\n","VAL Epoch [39]: [100/200]  Loss: [0.0335]\n","Best Epoch:  27 Best Loss:  0.10832797806244343\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"QhLlWxu1hdjl","colab_type":"text"},"source":["LOAD WEIGHTS STORED FOR THE BEST EPOCH"]},{"cell_type":"code","metadata":{"id":"XLhHSje0LRCb","colab_type":"code","outputId":"a4605008-4d9d-4d47-f952-e2cf1656417f","executionInfo":{"status":"ok","timestamp":1562098393898,"user_tz":-120,"elapsed":2069,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["weights = osp.join(weights_dir,args.resume+'.pth')\n","epoch = 28\n","if args.resume:\n","    print(weights)\n","    checkpoint = torch.load(weights)\n","    model.load_state_dict(checkpoint['model'])\n","    # Set the start epoch if it has not been\n","    if not args.start_epoch:\n","        args.start_epoch = checkpoint['epoch']"],"execution_count":16,"outputs":[{"output_type":"stream","text":["gdrive/My Drive/weights/checkpoint_e23_lr1e_3_40e_SGD.pth\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IWRpfAbXhjQ3","colab_type":"text"},"source":["COMPUTE SIMILARITIES AND PERCENTILES FOR THE VALIDATION SPLIT"]},{"cell_type":"code","metadata":{"id":"_BYWTUJCqpDa","colab_type":"code","outputId":"0966cff1-9d0f-42d2-861f-f595effe76d5","executionInfo":{"status":"ok","timestamp":1562098456719,"user_tz":-120,"elapsed":61676,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["import numpy as np\n","# View similarities\n","\n","sim_pos, sim_neg = val_sim_lim(model, val_loader, epoch, device=device)\n","pos_95 = np.percentile(sim_pos,95)\n","pos_5 = np.percentile(sim_pos,5)\n","pos_max = np.amax(sim_pos)\n","pos_min = np.amin(sim_pos)\n","print(pos_95, pos_5, pos_max, pos_min)\n","\n","neg_95 = np.percentile(sim_neg,95)\n","neg_5 = np.percentile(sim_neg,5)\n","neg_max = np.amax(sim_neg)\n","neg_min = np.amin(sim_neg)\n","print(neg_95, neg_5, neg_max, neg_min)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["VAL Epoch [28]: [0/200] \n","VAL Epoch [28]: [100/200] \n","0.9918118447065353 0.5256112039089202 0.9972943663597107 0.07290332764387131\n","0.9578584372997284 -0.1372625157237053 0.9923917055130005 -0.2736058235168457\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ngvxr3GMhuZR","colab_type":"text"},"source":["SELECT THRESHOLD"]},{"cell_type":"code","metadata":{"id":"1C7gxkZdyXnV","colab_type":"code","outputId":"9fcbac89-da7c-4c4c-a685-5fc9f6bba2c4","executionInfo":{"status":"ok","timestamp":1562100159058,"user_tz":-120,"elapsed":1673371,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy\n","\n","# Select threshold\n","best_acc = 0\n","best_tr = 0\n","sup = numpy.round(neg_95,decimals=3)\n","inf = numpy.round(pos_5,decimals=3)\n","for value in numpy.arange(inf, sup, 0.1):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","\n","sup = numpy.round(best_tr+.05,decimals=3)\n","inf = numpy.round(best_tr-.05,decimals=3)\n","for value in numpy.arange(inf, sup, 0.01):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","\n","sup = numpy.round(best_tr+.005,decimals=3)\n","inf = numpy.round(best_tr-.005,decimals=3)\n","for value in numpy.arange(inf, sup, 0.001):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","      \n","print('Best accuracy:', av_acc, 'Treshold:', best_tr)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.8214285714285714 Treshold: 0.526\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.8342857142857143 Treshold: 0.626\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5714285714285714]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.7142857142857143]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.835 Treshold: 0.646\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.8357142857142857 Treshold: 0.641\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [28]: [0/200]  Accuracy: [0.5]\n","VAL Epoch [28]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.835 Treshold: 0.641\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lLyWuWy-hz28","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR TEST"]},{"cell_type":"code","metadata":{"id":"TRHfMSYutwAS","colab_type":"code","outputId":"049063be-bf7e-454c-edcf-8139623d52c5","executionInfo":{"status":"ok","timestamp":1562098368620,"user_tz":-120,"elapsed":4464,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["test_loader = get_dataloader(args.split_testdata, args,\n","                             img_transforms=val_transforms, split=\"test\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","2800 samples in the test dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lHKc8T0Ih3KK","colab_type":"text"},"source":["RUN TEST"]},{"cell_type":"code","metadata":{"id":"EYZn9qBIuQ4O","colab_type":"code","outputId":"f4e82f6c-7533-40a0-87e2-fd1dea9ff288","executionInfo":{"status":"ok","timestamp":1562101374992,"user_tz":-120,"elapsed":100405,"user":{"displayName":"Sara Burrel Diez","photoUrl":"","userId":"15623305455276155381"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Test\n","\n","best_tr = 0.641\n","test_acc = test(model, loss_fn, test_loader, epoch, device=device, tr=best_tr)\n","av_acc = np.mean(test_acc)\n","print('Average test accuracy:', av_acc)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["TEST Epoch [28]: [0/200]  Accuracy: [0.7857142857142857]\n","TEST Epoch [28]: [100/200]  Accuracy: [0.7857142857142857]\n","Average test accuracy: 0.8567857142857142\n"],"name":"stdout"}]}]}