{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"siamesa_v4_sbd.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IYWZlB-mYTqY","colab_type":"text"},"source":["GENERAL IMPORTS AND SEED"]},{"cell_type":"code","metadata":{"id":"nwQ4Nmxgcmri","colab_type":"code","colab":{}},"source":["import argparse\n","import torch\n","import torchvision\n","from torch import optim\n","from torchvision import transforms\n","import os\n","import os.path as osp\n","import random\n","import numpy as np\n","from pathlib import Path\n","from torch.utils.data import dataset\n","import PIL\n","from PIL import Image\n","\n","# Fix the seed\n","seed = 1\n","\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","np.random.seed(seed)\n","random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EAo5WN-79ds","colab_type":"text"},"source":["ACCESS TO THE DRIVE FOLDER WHERE THE DATASET HAS BEEN STORED"]},{"cell_type":"code","metadata":{"id":"HLucYq9Loxgb","colab_type":"code","outputId":"a2d1e54f-816c-428e-fa3c-7404849afcb3","executionInfo":{"status":"ok","timestamp":1561795768081,"user_tz":-120,"elapsed":30337,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/'  #change dir to your project folder"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wHn2r5ERptEg","colab_type":"text"},"source":["DEFINE ARGUMENTS"]},{"cell_type":"code","metadata":{"id":"qdqM3jDv9VTI","colab_type":"code","colab":{}},"source":["class Args:\n","\n","    frontal_images_directories = \"gdrive/My Drive/dataset-cfp/Protocol/image_list_F.txt\"\n","    profile_images_directories = \"gdrive/My Drive/dataset-cfp/Protocol/image_list_P.txt\"\n","    split_main_directory = \"gdrive/My Drive/dataset-cfp/Protocol/Split\"\n","    split_traindata = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\n","    split_valdata = [\"07\", \"08\"]\n","    split_testdata = [\"09\", \"10\"]\n","    dataset_root = \"gdrive/My Drive\"\n","    dataset= \"CFPDataset\"\n","    lr = float(1e-4)\n","    weight_decay = float(0.0005)\n","    momentum = float(0.9)\n","    betas = (0.9, 0.999)\n","    batch_size = int(14)\n","    workers = int(8)\n","    start_epoch = int(0)\n","    epochs = int(14)\n","    #save_every = int(2)\n","    pretrained = True\n","    #siamese_linear = True\n","    data_aug = True\n","    resume = \"checkpoint_e33\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHNIGrMcpw6C","colab_type":"text"},"source":["DEFINE DATASET CLASS"]},{"cell_type":"code","metadata":{"id":"b_gAtqmHsofp","colab_type":"code","colab":{}},"source":["\n","class CFPDataset(dataset.Dataset):\n","    def __init__(self, path, args, img_transforms=None, dataset_root=\"\",\n","                 split=\"train\", input_size=(224, 224)):\n","        super().__init__()\n","\n","        self.data = []\n","        self.split = split\n","\n","        self.load(path, args)\n","\n","        print(\"Dataset loaded\")\n","        print(\"{0} samples in the {1} dataset\".format(len(self.data),\n","                                                      self.split))\n","        self.transforms = img_transforms\n","        self.dataset_root = dataset_root\n","        self.input_size = input_size\n","\n","    def load(self, path, args):\n","\n","        # read directories for frontal images\n","        lines = open(args.frontal_images_directories).readlines()\n","        idx = 0\n","        directories_frontal_images = []\n","        #print(len(lines))\n","        while idx < len(lines):\n","            x = lines[idx].strip().split()\n","            directories_frontal_images.append(x)\n","            idx += 1\n","        #print(x)\n","        # read directories for profile images\n","        lines = open(args.profile_images_directories).readlines()\n","        idx = 0\n","        directories_profile_images = []\n","        #print(len(lines))\n","        while idx < len(lines):\n","            x = lines[idx].strip().split()\n","            directories_profile_images.append(x)\n","            idx += 1\n","        #print(x)\n","        # read same and different pairs of images and save at dictionary\n","        self.data = []\n","        for i in path:\n","            ff_diff_file = osp.join(args.split_main_directory, 'FF', i,\n","                                    'diff.txt')\n","            lines = open(ff_diff_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_diff', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_frontal_images[int(img_pair[1])-1][1]\n","                pair_tag = -1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            ff_same_file = osp.join(args.split_main_directory, 'FF', i,\n","                                    'same.txt')\n","            lines = open(ff_same_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_same', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_frontal_images[int(img_pair[1])-1][1]\n","                pair_tag = 1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            fp_diff_file = osp.join(args.split_main_directory, 'FP', i,\n","                                    'diff.txt')\n","            lines = open(fp_diff_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('fp_diff', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_profile_images[int(img_pair[1])-1][1]\n","                pair_tag = -1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            fp_same_file = osp.join(args.split_main_directory, 'FP', i,\n","                                    'same.txt')\n","            lines = open(fp_same_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_same', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_profile_images[int(img_pair[1])-1][1]\n","                pair_tag = 1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        d = self.data[index]\n","        image1_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n","            'img1_path'])\n","        image2_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n","            'img2_path'])\n","        image1 = Image.open(image1_path).convert('RGB')\n","        image2 = Image.open(image2_path).convert('RGB')\n","        tag = d['pair_tag']\n","        if self.transforms is not None:\n","            # this converts from (HxWxC) to (CxHxW) as wel\n","            img1 = self.transforms(image1)\n","            img2 = self. transforms(image2)\n","\n","        return img1, img2, tag"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8p-RmAdvYrb6","colab_type":"text"},"source":["DEFINE DATA LOADER"]},{"cell_type":"code","metadata":{"id":"OYIFlDuZpiAR","colab_type":"code","colab":{}},"source":["from torch.utils import data\n","\n","def get_dataloader(datapath, args, img_transforms=None, split=\"train\"):\n","\n","    if split == 'train':\n","        shuffle = True\n","        drop_last = True\n","    else:\n","        shuffle = False\n","        drop_last = False\n","    \n","    dataset = CFPDataset(datapath,\n","                         args,\n","                         split=split,\n","                         img_transforms=img_transforms,\n","                         dataset_root=osp.expanduser(args.dataset_root))\n","    \n","    data_loader = data.DataLoader(dataset,\n","                                  batch_size=args.batch_size,\n","                                  shuffle=shuffle,    \n","                                  num_workers=args.workers,\n","                                  pin_memory=True,\n","                                  drop_last=drop_last)\n","    return data_loader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOTmj-LtqZnX","colab_type":"text"},"source":["DEFINE MODEL"]},{"cell_type":"code","metadata":{"id":"OboRfyRMqbP8","colab_type":"code","colab":{}},"source":["\n","import torch\n","from torch import nn\n","from torchvision.models import vgg16_bn\n","\n","def l2norm(x):\n","  x = x / torch.sqrt(torch.sum(x**2, dim=-1, keepdim=True))\n","  return x\n","\n","class SiameseCosine(nn.Module):\n","    \"\"\"\n","    Siamese network\n","    \"\"\"\n","    def __init__(self, pretrained=False):\n","        super(SiameseCosine, self).__init__()\n","\n","        vgg16_model = vgg16_bn(pretrained=pretrained)\n","        self.feat = vgg16_model.features\n","        self.linear_classifier = vgg16_model.classifier[0]\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n","\n","    def forward(self, img1, img2):\n","        feat_1 = self.feat(img1)\n","        feat_1 = self. avgpool(feat_1)\n","        feat_1 = feat_1.view(feat_1.size(0),-1)\n","        feat_1 = self.linear_classifier(feat_1)\n","        feat_1 = l2norm(feat_1)\n","        \n","        feat_2 = self.feat(img2)\n","        feat_2 = self. avgpool(feat_2)\n","        feat_2 = feat_2.view(feat_1.size(0),-1)\n","        feat_2 = self.linear_classifier(feat_2)\n","        feat_2 = l2norm(feat_2)\n","\n","      \n","        return feat_1, feat_2\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I7A5_ZZdqf8Z","colab_type":"text"},"source":["DEFINE LOSS"]},{"cell_type":"code","metadata":{"id":"VLLRaLvFqit5","colab_type":"code","colab":{}},"source":["from torch import nn\n","\n","class RecognitionCriterion(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.classification_criterion = nn.CosineEmbeddingLoss(margin=0.5).cuda()\n","        self.cls_loss = None\n","\n","    def forward(self, *input):\n","        self.cls_loss = self.classification_criterion(*input)\n","        return self.cls_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8c_WD2OCqnYa","colab_type":"text"},"source":["DEFINE TRAINING AND VALIDATION FUNCTIONS"]},{"cell_type":"code","metadata":{"id":"8c-eqydZqtKz","colab_type":"code","colab":{}},"source":["import torch\n","from torchvision import transforms\n","from torch.nn import functional as nnfunc\n","import numpy as np\n","\n","def similarity (vec1, vec2):\n","    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-8)\n","    cos_a = cos (vec1, vec2)  \n","    return cos_a\n","  \n","def accuracy(vec1, vec2, y, treshold):\n","    correct = 0\n","    total = 0\n","\n","    similarity_value = similarity(vec1, vec2)\n","   \n","    for value, label in zip(similarity_value, y):\n","        total += 1\n","        if value > treshold and label == 1.0:\n","            correct += 1\n","        if value < treshold and label == -1.0:\n","            correct += 1\n","    return correct/total\n","\n","def train(model, loss_fn, optimizer, dataloader, epoch, device):\n","    model.train()\n","    all_loss = []\n","        \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","     \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","   \n","        loss = loss_fn(out1, out2, prob) #calculates loss\n","        loss.backward() #upgrades gradients\n","        all_loss.append(loss.item())\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if idx % 100 == 0:\n","            message1 = \"TRAIN Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            #message2 = \"Loss: [{0:.4f}]; Accuracy: [{1}]\".format(loss.item(),\n","            #                                                    acc)\n","            message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_loss\n","\n","def val(model, loss_fn, dataloader, epoch, device):\n","    model.eval()\n","    all_loss = []\n","    \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","   \n","        loss = loss_fn(out1, out2, prob) #calculates loss\n","        all_loss.append(loss.item())\n","                  \n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            #message2 = \"Loss: [{0:.4f}]; Accuracy: [{1:.4f}]\".format(loss.item(),\n","            #                                                    acc)\n","            message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_loss\n","  \n","def val_sim_lim(model, dataloader, epoch, device):\n","    model.eval()\n","\n","    sim_pos_min = 1\n","    sim_neg_max = -1\n","    pos_similarities = []\n","    neg_similarities = []\n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","             \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","        \n","        sim = similarity(out1, out2)\n","        for value, label in zip(sim, prob):\n","            value = value.item()\n","            np.round(value, decimals=3)\n","            if label == 1:\n","                pos_similarities.append(value)\n","            else:\n","                neg_similarities.append(value)     \n","                \n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            print(message1)\n","        torch.cuda.empty_cache()\n","    return pos_similarities, neg_similarities\n","  \n","def val_tr(model, dataloader, epoch, device, tr):\n","    model.eval()\n","    all_loss = []\n","    all_acc = []  \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","           \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","\n","        acc = accuracy(out1, out2, prob, tr)\n","        all_acc.append(acc)\n","\n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            message2 = \"Accuracy: [{0}]\".format(acc)\n","            #message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_acc\n","  \n","  \n","def test(model, loss_fn, dataloader, epoch, device, tr):\n","    #model = model.to(device)\n","    model.eval()\n","    all_acc = []\n","        \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","     \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","\n","        acc = accuracy(out1, out2, prob, tr)\n","        all_acc.append(acc)\n","\n","        if idx % 100 == 0:\n","            message1 = \"TEST Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            message2 = \"Accuracy: [{0}]\".format(acc)\n","            #message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zyDE1B5lY7vM","colab_type":"text"},"source":["LOAD ARGUMENTS AND DEFINE IMAGE TRANSFORMS"]},{"cell_type":"code","metadata":{"id":"8iZoeeWM9umb","colab_type":"code","colab":{}},"source":["args = Args()\n","\n","train_transform=None\n","if args.data_aug == False:\n","  img_transforms = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n","\n","else:\n","  img_transforms = transforms.Compose([transforms.Resize((224, 224)), \n","                                        transforms.RandomHorizontalFlip(), \n","                                        transforms.RandomRotation(20, resample=PIL.Image.BILINEAR), \n","                                        transforms.ToTensor()])\n","\n","    \n","\n","val_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHMvvFs_ZCjH","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR TRAINING"]},{"cell_type":"code","metadata":{"id":"yGzZEm6j94ML","colab_type":"code","outputId":"41efc6bd-a41c-4d76-f05d-7d5fb2ae3244","executionInfo":{"status":"ok","timestamp":1561796115076,"user_tz":-120,"elapsed":9617,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["train_loader = get_dataloader(args.split_traindata, args,\n","                              img_transforms=img_transforms)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","8400 samples in the train dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"axfTIzs3ZHUJ","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR VALIDATION"]},{"cell_type":"code","metadata":{"id":"FKQgt_NDrA5L","colab_type":"code","outputId":"cba1f2b6-28d3-40f2-dbc6-fd2b5d8a01a6","executionInfo":{"status":"ok","timestamp":1561796120006,"user_tz":-120,"elapsed":2966,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["val_loader = get_dataloader(args.split_valdata, args,\n","                            img_transforms=val_transforms, split=\"val\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","2800 samples in the val dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pZzz8_zNZSZy","colab_type":"text"},"source":["SPECIFY DEVICE"]},{"cell_type":"code","metadata":{"id":"NJU0i3PpLAHm","colab_type":"code","outputId":"d07959da-dd8c-45dd-962c-5c945c86a43f","executionInfo":{"status":"ok","timestamp":1561796122842,"user_tz":-120,"elapsed":835,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.cuda.is_available()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"X8NbSOen-wOy","colab_type":"code","colab":{}},"source":["# check for CUDA\n","if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDOrR0gpZdpW","colab_type":"text"},"source":["LOAD MODEL"]},{"cell_type":"code","metadata":{"id":"5c6akqfUTcp2","colab_type":"code","outputId":"92bc6e63-f0ec-4ca8-a27b-56efe80eeb61","executionInfo":{"status":"ok","timestamp":1561796315673,"user_tz":-120,"elapsed":3125,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":975}},"source":["# LOAD MODEL\n","model = SiameseCosine()\n","#CHECK LAYERS STATE\n","print(\"State of the features layers: \\n\")\n","for name, child in model.feat.named_children():\n","  for name_2, params in child.named_parameters():\n","    print(child, name_2, params.requires_grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["State of the features layers: \n","\n","Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MRZphEA-ZgY6","colab_type":"text"},"source":["FREEZE LAYERS"]},{"cell_type":"code","metadata":{"id":"LKiIcmFGUM_X","colab_type":"code","outputId":"3da129e2-2ff0-4cf8-887e-1cb395d65174","executionInfo":{"status":"ok","timestamp":1561796452186,"user_tz":-120,"elapsed":1449,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":975}},"source":["nConv = 7 # Num of conv layers that we freeze\n","features_freezed = 0\n","for name, child in model.feat.named_children():\n","   if features_freezed < nConv:\n","    if isinstance(child,torch.nn.modules.conv.Conv2d): features_freezed+=1\n","    for name2, params in child.named_parameters():\n","      params.requires_grad = False\n","\n","\n","#Check required_grad (false)\n","print(\"State of the features layers: \\n\")\n","for name, child in model.feat.named_children():\n","  for name_2, params in child.named_parameters():\n","    print(child, name_2, params.requires_grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["State of the features layers: \n","\n","Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight False\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias False\n","Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight False\n","BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias False\n","Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight False\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias False\n","Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight False\n","BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias False\n","Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight False\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias False\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight False\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias False\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight False\n","Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias False\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight True\n","Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) bias True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) weight True\n","BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) bias True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6GcVWnn7Z1Dj","colab_type":"text"},"source":["MOVE MODEL TO DEVICE AND SELECT LOSS FUNCTION"]},{"cell_type":"code","metadata":{"id":"_cTc5vSct0U4","colab_type":"code","colab":{}},"source":["\n","model = model.to(device) # treure de train i validation\n","\n","loss_fn = RecognitionCriterion()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lmgJOylhaHD3","colab_type":"text"},"source":["SPECIFY WEIGHTS DIRECTORY"]},{"cell_type":"code","metadata":{"id":"ZFg3godAt06I","colab_type":"code","colab":{}},"source":["# directory where we'll store model weights\n","weights_dir = \"gdrive/My Drive/weights\"\n","if not osp.exists(weights_dir):\n","    os.mkdir(weights_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HaQXufdaLAf","colab_type":"text"},"source":["SELECT OPTIMIZER"]},{"cell_type":"code","metadata":{"id":"kRW8oa-H-3gT","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,\n","                             weight_decay=args.weight_decay)\n","\n","#optimizer = optim.SGD(model.parameters(), lr=args.lr,\n","#                      momentum=args.momentum, weight_decay=args.weight_decay)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CG3VxZP9aOVE","colab_type":"text"},"source":["DEFINE CHECKPOINT"]},{"cell_type":"code","metadata":{"id":"WAS5FOei-8T1","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, filename=\"checkpoint.pth\", save_path=weights_dir):\n","    # check if the save directory exists\n","    if not Path(save_path).exists():\n","        Path(save_path).mkdir()\n","\n","    save_path = Path(save_path, filename)\n","    torch.save(state, str(save_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PFaea2yxaQvd","colab_type":"text"},"source":["RUN TRAIN"]},{"cell_type":"code","metadata":{"id":"E0ddySP2_DPR","colab_type":"code","outputId":"3690a3d5-6001-4dc9-8675-e7d4e79ae20b","executionInfo":{"status":"ok","timestamp":1561801956058,"user_tz":-120,"elapsed":5456054,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","# train and evalute for `epochs`\n","loss_epoch_train = []\n","loss_epoch_val = []\n","acc_epoch_train = []\n","acc_epoch_val = []\n","\n","best_loss = 100\n","best_epoch = 0\n","\n","for epoch in range(args.start_epoch, args.epochs):\n","    train_loss = train(model, loss_fn, optimizer, train_loader, epoch, device=device)\n","    \n","    av_loss = np.mean(train_loss)\n","    loss_epoch_train.append(av_loss)\n","\n","\n","    val_loss = val(model, loss_fn, val_loader, epoch, device=device)\n","    \n","    av_loss = np.mean(val_loss)\n","    loss_epoch_val.append(av_loss)\n","\n","    if best_loss > av_loss:\n","        best_loss = av_loss\n","        best_epoch = epoch\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'batch_size': val_loader.batch_size,\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","         }, filename=str(args.resume)+\".pth\",\n","             save_path=weights_dir)\n","    \n","print(\"Best Epoch: \",best_epoch, \"Best Loss: \", best_loss)\n","    \n","epochs = range(1, len(loss_epoch_train) + 1)\n","# b is for \"solid blue line\"\n","plt.plot(epochs, loss_epoch_train, 'b', label='Training loss')\n","# r is for \"solid red line\"\n","plt.plot(epochs, loss_epoch_val, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","#epochs = range(1, len(acc_epoch_train) + 1)\n","# b is for \"solid blue line\"\n","#plt.plot(epochs, acc_epoch_train, 'b', label='Training accuracy')\n","# r is for \"solid red line\"\n","#plt.plot(epochs, acc_epoch_val, 'r', label='Validation accuracy')\n","#plt.title('Training and validation accuracy')\n","#plt.xlabel('Epochs')\n","#plt.ylabel('Accuracy')\n","#plt.legend()\n","#plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAIN Epoch [0]: [0/600]  Loss: [0.2997]\n","TRAIN Epoch [0]: [100/600]  Loss: [0.2466]\n","TRAIN Epoch [0]: [200/600]  Loss: [0.1942]\n","TRAIN Epoch [0]: [300/600]  Loss: [0.2802]\n","TRAIN Epoch [0]: [400/600]  Loss: [0.1303]\n","TRAIN Epoch [0]: [500/600]  Loss: [0.2764]\n","VAL Epoch [0]: [0/200]  Loss: [0.4436]\n","VAL Epoch [0]: [100/200]  Loss: [0.1538]\n","TRAIN Epoch [1]: [0/600]  Loss: [0.1568]\n","TRAIN Epoch [1]: [100/600]  Loss: [0.1648]\n","TRAIN Epoch [1]: [200/600]  Loss: [0.1637]\n","TRAIN Epoch [1]: [300/600]  Loss: [0.0981]\n","TRAIN Epoch [1]: [400/600]  Loss: [0.1466]\n","TRAIN Epoch [1]: [500/600]  Loss: [0.1684]\n","VAL Epoch [1]: [0/200]  Loss: [0.3878]\n","VAL Epoch [1]: [100/200]  Loss: [0.1708]\n","TRAIN Epoch [2]: [0/600]  Loss: [0.1883]\n","TRAIN Epoch [2]: [100/600]  Loss: [0.1970]\n","TRAIN Epoch [2]: [200/600]  Loss: [0.0919]\n","TRAIN Epoch [2]: [300/600]  Loss: [0.1143]\n","TRAIN Epoch [2]: [400/600]  Loss: [0.2041]\n","TRAIN Epoch [2]: [500/600]  Loss: [0.2314]\n","VAL Epoch [2]: [0/200]  Loss: [0.4232]\n","VAL Epoch [2]: [100/200]  Loss: [0.2008]\n","TRAIN Epoch [3]: [0/600]  Loss: [0.1363]\n","TRAIN Epoch [3]: [100/600]  Loss: [0.1226]\n","TRAIN Epoch [3]: [200/600]  Loss: [0.2301]\n","TRAIN Epoch [3]: [300/600]  Loss: [0.0572]\n","TRAIN Epoch [3]: [400/600]  Loss: [0.1281]\n","TRAIN Epoch [3]: [500/600]  Loss: [0.1912]\n","VAL Epoch [3]: [0/200]  Loss: [0.2418]\n","VAL Epoch [3]: [100/200]  Loss: [0.1424]\n","TRAIN Epoch [4]: [0/600]  Loss: [0.1932]\n","TRAIN Epoch [4]: [100/600]  Loss: [0.1474]\n","TRAIN Epoch [4]: [200/600]  Loss: [0.2727]\n","TRAIN Epoch [4]: [300/600]  Loss: [0.0766]\n","TRAIN Epoch [4]: [400/600]  Loss: [0.1851]\n","TRAIN Epoch [4]: [500/600]  Loss: [0.0929]\n","VAL Epoch [4]: [0/200]  Loss: [0.3892]\n","VAL Epoch [4]: [100/200]  Loss: [0.1538]\n","TRAIN Epoch [5]: [0/600]  Loss: [0.0908]\n","TRAIN Epoch [5]: [100/600]  Loss: [0.2521]\n","TRAIN Epoch [5]: [200/600]  Loss: [0.1849]\n","TRAIN Epoch [5]: [300/600]  Loss: [0.1358]\n","TRAIN Epoch [5]: [400/600]  Loss: [0.1574]\n","TRAIN Epoch [5]: [500/600]  Loss: [0.1208]\n","VAL Epoch [5]: [0/200]  Loss: [0.3300]\n","VAL Epoch [5]: [100/200]  Loss: [0.1377]\n","TRAIN Epoch [6]: [0/600]  Loss: [0.0455]\n","TRAIN Epoch [6]: [100/600]  Loss: [0.1412]\n","TRAIN Epoch [6]: [200/600]  Loss: [0.1847]\n","TRAIN Epoch [6]: [300/600]  Loss: [0.1370]\n","TRAIN Epoch [6]: [400/600]  Loss: [0.0783]\n","TRAIN Epoch [6]: [500/600]  Loss: [0.1785]\n","VAL Epoch [6]: [0/200]  Loss: [0.4088]\n","VAL Epoch [6]: [100/200]  Loss: [0.1739]\n","TRAIN Epoch [7]: [0/600]  Loss: [0.1300]\n","TRAIN Epoch [7]: [100/600]  Loss: [0.1811]\n","TRAIN Epoch [7]: [200/600]  Loss: [0.1036]\n","TRAIN Epoch [7]: [300/600]  Loss: [0.2568]\n","TRAIN Epoch [7]: [400/600]  Loss: [0.1344]\n","TRAIN Epoch [7]: [500/600]  Loss: [0.1423]\n","VAL Epoch [7]: [0/200]  Loss: [0.3129]\n","VAL Epoch [7]: [100/200]  Loss: [0.1478]\n","TRAIN Epoch [8]: [0/600]  Loss: [0.1945]\n","TRAIN Epoch [8]: [100/600]  Loss: [0.2031]\n","TRAIN Epoch [8]: [200/600]  Loss: [0.1776]\n","TRAIN Epoch [8]: [300/600]  Loss: [0.2106]\n","TRAIN Epoch [8]: [400/600]  Loss: [0.1745]\n","TRAIN Epoch [8]: [500/600]  Loss: [0.1411]\n","VAL Epoch [8]: [0/200]  Loss: [0.2183]\n","VAL Epoch [8]: [100/200]  Loss: [0.0854]\n","TRAIN Epoch [9]: [0/600]  Loss: [0.1691]\n","TRAIN Epoch [9]: [100/600]  Loss: [0.1134]\n","TRAIN Epoch [9]: [200/600]  Loss: [0.2373]\n","TRAIN Epoch [9]: [300/600]  Loss: [0.0841]\n","TRAIN Epoch [9]: [400/600]  Loss: [0.2519]\n","TRAIN Epoch [9]: [500/600]  Loss: [0.1982]\n","VAL Epoch [9]: [0/200]  Loss: [0.2862]\n","VAL Epoch [9]: [100/200]  Loss: [0.1021]\n","TRAIN Epoch [10]: [0/600]  Loss: [0.1444]\n","TRAIN Epoch [10]: [100/600]  Loss: [0.1251]\n","TRAIN Epoch [10]: [200/600]  Loss: [0.1209]\n","TRAIN Epoch [10]: [300/600]  Loss: [0.0858]\n","TRAIN Epoch [10]: [400/600]  Loss: [0.1326]\n","TRAIN Epoch [10]: [500/600]  Loss: [0.1647]\n","VAL Epoch [10]: [0/200]  Loss: [0.2596]\n","VAL Epoch [10]: [100/200]  Loss: [0.1016]\n","TRAIN Epoch [11]: [0/600]  Loss: [0.1640]\n","TRAIN Epoch [11]: [100/600]  Loss: [0.1425]\n","TRAIN Epoch [11]: [200/600]  Loss: [0.0949]\n","TRAIN Epoch [11]: [300/600]  Loss: [0.1143]\n","TRAIN Epoch [11]: [400/600]  Loss: [0.1918]\n","TRAIN Epoch [11]: [500/600]  Loss: [0.1409]\n","VAL Epoch [11]: [0/200]  Loss: [0.2885]\n","VAL Epoch [11]: [100/200]  Loss: [0.1246]\n","TRAIN Epoch [12]: [0/600]  Loss: [0.0624]\n","TRAIN Epoch [12]: [100/600]  Loss: [0.1523]\n","TRAIN Epoch [12]: [200/600]  Loss: [0.1790]\n","TRAIN Epoch [12]: [300/600]  Loss: [0.1100]\n","TRAIN Epoch [12]: [400/600]  Loss: [0.0811]\n","TRAIN Epoch [12]: [500/600]  Loss: [0.1718]\n","VAL Epoch [12]: [0/200]  Loss: [0.2939]\n","VAL Epoch [12]: [100/200]  Loss: [0.1155]\n","TRAIN Epoch [13]: [0/600]  Loss: [0.0975]\n","TRAIN Epoch [13]: [100/600]  Loss: [0.1483]\n","TRAIN Epoch [13]: [200/600]  Loss: [0.1370]\n","TRAIN Epoch [13]: [300/600]  Loss: [0.1326]\n","TRAIN Epoch [13]: [400/600]  Loss: [0.1394]\n","TRAIN Epoch [13]: [500/600]  Loss: [0.2469]\n","VAL Epoch [13]: [0/200]  Loss: [0.2664]\n","VAL Epoch [13]: [100/200]  Loss: [0.0954]\n","Best Epoch:  12 Best Loss:  0.1409986862493679\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlicL55xzYf0/CLbfwFT5qAYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Pvz_toyoaVfr","colab_type":"text"},"source":["LOAD STORED WEIGHTS"]},{"cell_type":"code","metadata":{"id":"XLhHSje0LRCb","colab_type":"code","outputId":"b6e2f229-2e78-449c-b04b-80f254860a1f","executionInfo":{"status":"ok","timestamp":1561804002512,"user_tz":-120,"elapsed":2864,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["weights = osp.join(weights_dir,args.resume+'.pth')\n","epoch = 13\n","if args.resume:\n","    print(weights)\n","    checkpoint = torch.load(weights)\n","    model.load_state_dict(checkpoint['model'])\n","    #optimizer.load_state_dict(checkpoint['optimizer'])\n","    # Set the start epoch if it has not been\n","    if not args.start_epoch:\n","        args.start_epoch = checkpoint['epoch']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gdrive/My Drive/weights/checkpoint_e33.pth\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QaL6ABHKadCY","colab_type":"text"},"source":["COMPUTE SIMILARITIES AND PERCENTILS FOR THE VALIDATION SPLIT"]},{"cell_type":"code","metadata":{"id":"_BYWTUJCqpDa","colab_type":"code","outputId":"62570203-fd0b-442d-d246-982bde70e261","executionInfo":{"status":"ok","timestamp":1561804058824,"user_tz":-120,"elapsed":54913,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["import numpy as np\n","# View similarities\n","\n","sim_pos, sim_neg = val_sim_lim(model, val_loader, epoch, device=device)\n","pos_95 = np.percentile(sim_pos,95)\n","pos_5 = np.percentile(sim_pos,5)\n","pos_max = np.amax(sim_pos)\n","pos_min = np.amin(sim_pos)\n","print(pos_95, pos_5, pos_max, pos_min)\n","\n","neg_95 = np.percentile(sim_neg,95)\n","neg_5 = np.percentile(sim_neg,5)\n","neg_max = np.amax(sim_neg)\n","neg_min = np.amin(sim_neg)\n","print(neg_95, neg_5, neg_max, neg_min)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["VAL Epoch [13]: [0/200] \n","VAL Epoch [13]: [100/200] \n","0.9968381971120834 0.6692144304513932 0.9996171593666077 -0.021190255880355835\n","0.986639466881752 0.02878280729055405 0.9994738698005676 -0.21002382040023804\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OWMYk11Eau5W","colab_type":"text"},"source":["SELECT THRESHOLD"]},{"cell_type":"code","metadata":{"id":"1C7gxkZdyXnV","colab_type":"code","outputId":"927468d3-3a35-4bcc-b88b-5c46d5fe7204","executionInfo":{"status":"ok","timestamp":1561715094378,"user_tz":-120,"elapsed":1569686,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":920}},"source":["import numpy\n","\n","# Select threshold\n","best_acc = 0\n","best_tr = 0\n","sup = numpy.round(neg_95,decimals=3)\n","for value in numpy.arange(inf, sup, 0.1):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","\n","sup = numpy.round(best_tr+.05,decimals=3)\n","inf = numpy.round(best_tr-.05,decimals=3)\n","for value in numpy.arange(inf, sup, 0.01):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","\n","sup = numpy.round(best_tr+.005,decimals=3)\n","inf = numpy.round(best_tr-.005,decimals=3)\n","for value in numpy.arange(inf, sup, 0.001):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","      \n","print('Best accuracy:', av_acc, 'Treshold:', best_tr)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7142857142857143]\n","Best accuracy: 0.7417857142857142 Treshold: 0.669\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","Best accuracy: 0.745 Treshold: 0.769\n","VAL Epoch [13]: [0/200]  Accuracy: [0.42857142857142855]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [13]: [100/200]  Accuracy: [1.0]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","Best accuracy: 0.7460714285714286 Treshold: 0.779\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.42857142857142855]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.42857142857142855]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n","VAL Epoch [13]: [100/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [13]: [0/200]  Accuracy: [0.35714285714285715]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yIbxpMigbE-x","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR TEST"]},{"cell_type":"code","metadata":{"id":"TRHfMSYutwAS","colab_type":"code","outputId":"16958363-caa5-48ae-b9c1-bc6e4ec33f1f","executionInfo":{"status":"ok","timestamp":1561716151376,"user_tz":-120,"elapsed":6940,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["test_loader = get_dataloader(args.split_testdata, args,\n","                             img_transforms=val_transforms, split=\"test\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","2800 samples in the test dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ffUF_uG-bH1y","colab_type":"text"},"source":["RUN TEST"]},{"cell_type":"code","metadata":{"id":"EYZn9qBIuQ4O","colab_type":"code","outputId":"8abbdfc6-91fe-46f6-94e5-ce22b8498dd2","executionInfo":{"status":"ok","timestamp":1561716307531,"user_tz":-120,"elapsed":144053,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Test\n","\n","best_tr = 0.709\n","test_acc = test(model, loss_fn, test_loader, epoch, device=device, tr=best_tr)\n","av_acc = np.mean(test_acc)\n","print('Average test accuracy:', av_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TEST Epoch [12]: [0/200]  Accuracy: [0.5714285714285714]\n","TEST Epoch [12]: [100/200]  Accuracy: [0.9285714285714286]\n","Average test accuracy: 0.8182142857142858\n"],"name":"stdout"}]}]}