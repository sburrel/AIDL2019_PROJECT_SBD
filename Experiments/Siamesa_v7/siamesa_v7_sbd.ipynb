{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"siamesa_v7_sbd.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NmBJ8XlZd_k1","colab_type":"text"},"source":["DEFINE GENERAL ARGUMENTS AND SEED"]},{"cell_type":"code","metadata":{"id":"nwQ4Nmxgcmri","colab_type":"code","colab":{}},"source":["import argparse\n","import torch\n","import torchvision\n","from torch import optim\n","from torchvision import transforms\n","import os\n","import os.path as osp\n","import random\n","import numpy as np\n","from pathlib import Path\n","from torch.utils.data import dataset\n","import PIL\n","from PIL import Image\n","\n","# fix the seed\n","seed = 1\n","\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","np.random.seed(seed)\n","random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EAo5WN-79ds","colab_type":"text"},"source":["ACCESS TO THE DRIVE FOLDER WHERE THE DATASET HAS BEEN STORED"]},{"cell_type":"code","metadata":{"id":"HLucYq9Loxgb","colab_type":"code","outputId":"a6dcfc6c-caec-4c51-dbb3-55142b7b420c","executionInfo":{"status":"ok","timestamp":1561983075049,"user_tz":-120,"elapsed":27159,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/'  #change dir to your project folder"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wHn2r5ERptEg","colab_type":"text"},"source":["DEFINE ARGUMENTS"]},{"cell_type":"code","metadata":{"id":"qdqM3jDv9VTI","colab_type":"code","colab":{}},"source":["class Args:\n","\n","    frontal_images_directories = \"gdrive/My Drive/dataset-cfp/Protocol/image_list_F.txt\"\n","    profile_images_directories = \"gdrive/My Drive/dataset-cfp/Protocol/image_list_P.txt\"\n","    split_main_directory = \"gdrive/My Drive/dataset-cfp/Protocol/Split\"\n","    split_traindata = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\n","    split_valdata = [\"07\", \"08\"]\n","    split_testdata = [\"09\", \"10\"]\n","    dataset_root = \"gdrive/My Drive\"\n","    dataset= \"CFPDataset\"\n","    lr = float(1e-3)\n","    weight_decay = float(0.0005)\n","    momentum = float(0.9)\n","    betas = (0.9, 0.999)\n","    batch_size = int(14)\n","    workers = int(8)\n","    start_epoch = int(0)\n","    epochs = int(40)\n","    #save_every = int(2)\n","    pretrained = True\n","    #siamese_linear = True\n","    data_aug = True\n","    resume = \"checkpoint_e63_40e_lr1e_3_SGD\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHNIGrMcpw6C","colab_type":"text"},"source":["DEFINE DATASET CLASS"]},{"cell_type":"code","metadata":{"id":"b_gAtqmHsofp","colab_type":"code","colab":{}},"source":["\n","class CFPDataset(dataset.Dataset):\n","    def __init__(self, path, args, img_transforms=None, dataset_root=\"\",\n","                 split=\"train\", input_size=(224, 224)):\n","        super().__init__()\n","\n","        self.data = []\n","        self.split = split\n","\n","        self.load(path, args)\n","\n","        print(\"Dataset loaded\")\n","        print(\"{0} samples in the {1} dataset\".format(len(self.data),\n","                                                      self.split))\n","        self.transforms = img_transforms\n","        self.dataset_root = dataset_root\n","        self.input_size = input_size\n","\n","    def load(self, path, args):\n","\n","        # read directories for frontal images\n","        lines = open(args.frontal_images_directories).readlines()\n","        idx = 0\n","        directories_frontal_images = []\n","        #print(len(lines))\n","        while idx < len(lines):\n","            x = lines[idx].strip().split()\n","            directories_frontal_images.append(x)\n","            idx += 1\n","        #print(x)\n","        # read directories for profile images\n","        lines = open(args.profile_images_directories).readlines()\n","        idx = 0\n","        directories_profile_images = []\n","        #print(len(lines))\n","        while idx < len(lines):\n","            x = lines[idx].strip().split()\n","            directories_profile_images.append(x)\n","            idx += 1\n","        #print(x)\n","        # read same and different pairs of images and save at dictionary\n","        self.data = []\n","        for i in path:\n","            ff_diff_file = osp.join(args.split_main_directory, 'FF', i,\n","                                    'diff.txt')\n","            lines = open(ff_diff_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_diff', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_frontal_images[int(img_pair[1])-1][1]\n","                pair_tag = -1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            ff_same_file = osp.join(args.split_main_directory, 'FF', i,\n","                                    'same.txt')\n","            lines = open(ff_same_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_same', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_frontal_images[int(img_pair[1])-1][1]\n","                pair_tag = 1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            fp_diff_file = osp.join(args.split_main_directory, 'FP', i,\n","                                    'diff.txt')\n","            lines = open(fp_diff_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('fp_diff', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_profile_images[int(img_pair[1])-1][1]\n","                pair_tag = -1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","            fp_same_file = osp.join(args.split_main_directory, 'FP', i,\n","                                    'same.txt')\n","            lines = open(fp_same_file).readlines()\n","            idx = 0\n","            while idx < int(len(lines)/1):\n","                img_pair = lines[idx].strip().split(',')\n","                #print('ff_same', img_pair)\n","                img1_dir = directories_frontal_images[int(img_pair[0])-1][1]\n","                img2_dir = directories_profile_images[int(img_pair[1])-1][1]\n","                pair_tag = 1\n","                d = {\n","                    \"img1_path\": img1_dir,\n","                    \"img2_path\": img2_dir,\n","                    \"pair_tag\": pair_tag\n","                }\n","                #print(d)\n","                self.data.append(d)\n","                idx += 1\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        d = self.data[index]\n","        image1_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n","            'img1_path'])\n","        image2_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n","            'img2_path'])\n","        image1 = Image.open(image1_path).convert('RGB')\n","        image2 = Image.open(image2_path).convert('RGB')\n","        tag = d['pair_tag']\n","        if self.transforms is not None:\n","            # this converts from (HxWxC) to (CxHxW) as wel\n","            img1 = self.transforms(image1)\n","            img2 = self. transforms(image2)\n","\n","        return img1, img2, tag"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QbfxPOakeRS2","colab_type":"text"},"source":["DEFINE DATA LOADES"]},{"cell_type":"code","metadata":{"id":"OYIFlDuZpiAR","colab_type":"code","colab":{}},"source":["from torch.utils import data\n","\n","def get_dataloader(datapath, args, img_transforms=None, split=\"train\"):\n","\n","    if split == 'train':\n","        shuffle = True\n","        drop_last = True\n","    else:\n","        shuffle = False\n","        drop_last = False\n","    \n","    dataset = CFPDataset(datapath,\n","                         args,\n","                         split=split,\n","                         img_transforms=img_transforms,\n","                         dataset_root=osp.expanduser(args.dataset_root))\n","    \n","    data_loader = data.DataLoader(dataset,\n","                                  batch_size=args.batch_size,\n","                                  shuffle=shuffle,    \n","                                  num_workers=args.workers,\n","                                  pin_memory=True,\n","                                  drop_last=drop_last)\n","    return data_loader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOTmj-LtqZnX","colab_type":"text"},"source":["DEFINE MODEL"]},{"cell_type":"code","metadata":{"id":"OboRfyRMqbP8","colab_type":"code","colab":{}},"source":["\n","import torch\n","from torch import nn\n","from torchvision.models import resnext50_32x4d\n","\n","def l2norm(x):\n","  x = x / torch.sqrt(torch.sum(x**2, dim=-1, keepdim=True))\n","  return x\n","\n","class SiameseCosine(nn.Module):\n","    \"\"\"\n","    Siamese network\n","    \"\"\"\n","    def __init__(self, pretrained=False):\n","        super(SiameseCosine, self).__init__()\n","\n","        resnext50_32x4d_model = resnext50_32x4d(pretrained=pretrained)\n","        self.feat = resnext50_32x4d_model\n","        \n","    def forward(self, img1, img2):\n","        feat_1 = self.feat(img1)\n","        feat_1 = l2norm(feat_1)\n","        \n","        feat_2 = self.feat(img2)\n","        feat_2 = l2norm(feat_2)\n","\n","      \n","        return feat_1, feat_2\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I7A5_ZZdqf8Z","colab_type":"text"},"source":["DEFINE LOSS"]},{"cell_type":"code","metadata":{"id":"VLLRaLvFqit5","colab_type":"code","colab":{}},"source":["from torch import nn\n","\n","class RecognitionCriterion(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.classification_criterion = nn.CosineEmbeddingLoss(margin=0.5).cuda()\n","        self.cls_loss = None\n","\n","    def forward(self, *input):\n","        self.cls_loss = self.classification_criterion(*input)\n","        return self.cls_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8c_WD2OCqnYa","colab_type":"text"},"source":["DEFINE TRAINING AND VALIDATION FUNCTIONS"]},{"cell_type":"code","metadata":{"id":"8c-eqydZqtKz","colab_type":"code","colab":{}},"source":["import torch\n","from torchvision import transforms\n","from torch.nn import functional as nnfunc\n","import numpy as np\n","\n","def similarity (vec1, vec2):\n","    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-8)\n","    cos_a = cos (vec1, vec2)  \n","    return cos_a\n","  \n","def accuracy(vec1, vec2, y, treshold):\n","    correct = 0\n","    total = 0\n","\n","    similarity_value = similarity(vec1, vec2)\n","   \n","    for value, label in zip(similarity_value, y):\n","        total += 1\n","        if value > treshold and label == 1.0:\n","            correct += 1\n","        if value < treshold and label == -1.0:\n","            correct += 1\n","    return correct/total\n","\n","def train(model, loss_fn, optimizer, dataloader, epoch, device):\n","    model.train()\n","    all_loss = []\n","        \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","     \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","   \n","        loss = loss_fn(out1, out2, prob) #calculates loss\n","        loss.backward() #upgrades gradients\n","        all_loss.append(loss.item())\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if idx % 100 == 0:\n","            message1 = \"TRAIN Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            #message2 = \"Loss: [{0:.4f}]; Accuracy: [{1}]\".format(loss.item(),\n","            #                                                    acc)\n","            message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_loss\n","\n","def val(model, loss_fn, dataloader, epoch, device):\n","    model.eval()\n","    all_loss = []\n","    \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","   \n","        loss = loss_fn(out1, out2, prob) #calculates loss\n","        all_loss.append(loss.item())\n","                  \n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            #message2 = \"Loss: [{0:.4f}]; Accuracy: [{1:.4f}]\".format(loss.item(),\n","            #                                                    acc)\n","            message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_loss\n","  \n","def val_sim_lim(model, dataloader, epoch, device):\n","    model.eval()\n","\n","    sim_pos_min = 1\n","    sim_neg_max = -1\n","    pos_similarities = []\n","    neg_similarities = []\n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","             \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","        \n","        sim = similarity(out1, out2)\n","        for value, label in zip(sim, prob):\n","            value = value.item()\n","            np.round(value, decimals=3)\n","            if label == 1:\n","                pos_similarities.append(value)\n","            else:\n","                neg_similarities.append(value)     \n","                \n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            print(message1)\n","        torch.cuda.empty_cache()\n","    return pos_similarities, neg_similarities\n","  \n","def val_tr(model, dataloader, epoch, device, tr):\n","    model.eval()\n","    all_loss = []\n","    all_acc = []  \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","           \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","\n","        acc = accuracy(out1, out2, prob, tr)\n","        all_acc.append(acc)\n","\n","        if idx % 100 == 0:\n","            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            message2 = \"Accuracy: [{0}]\".format(acc)\n","            #message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_acc\n","  \n","  \n","def test(model, loss_fn, dataloader, epoch, device, tr):\n","    #model = model.to(device)\n","    model.eval()\n","    all_acc = []\n","        \n","    for idx, (img1, img2, prob) in enumerate(dataloader):\n","        img1 =  img1.to('cuda:0')\n","        img2 = img2.to('cuda:0')\n","        prob = prob.float().to('cuda:0')  #label\n","        \n","     \n","        out1, out2 = model(img1, img2) #inputs images to model, executes model, returns features\n","\n","        acc = accuracy(out1, out2, prob, tr)\n","        all_acc.append(acc)\n","\n","        if idx % 100 == 0:\n","            message1 = \"TEST Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n","                                                              len(dataloader))\n","            message2 = \"Accuracy: [{0}]\".format(acc)\n","            #message2 = \"Loss: [{0:.4f}]\".format(loss.item())\n","            print(message1, message2)\n","        torch.cuda.empty_cache()\n","    return all_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9DYA_2HeeZKZ","colab_type":"text"},"source":["LOAD ARGUMENTS AND DEFINE IMAGE TRANSFORMATIONS"]},{"cell_type":"code","metadata":{"id":"8iZoeeWM9umb","colab_type":"code","colab":{}},"source":["args = Args()\n","\n","train_transform=None\n","if args.data_aug == False:\n","  img_transforms = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n","\n","else:\n","  img_transforms = transforms.Compose([transforms.Resize((224, 224)), \n","                                        transforms.RandomHorizontalFlip(), \n","                                        transforms.RandomRotation(20, resample=PIL.Image.BILINEAR), \n","                                        transforms.ToTensor()])\n","\n","    \n","\n","val_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1wkggmSJeeHV","colab_type":"text"},"source":["LOAD DATASET FOR TRAINING"]},{"cell_type":"code","metadata":{"id":"yGzZEm6j94ML","colab_type":"code","outputId":"3af9dc92-997b-4fde-8fbf-5774c818a7ec","executionInfo":{"status":"ok","timestamp":1561983141655,"user_tz":-120,"elapsed":8815,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["train_loader = get_dataloader(args.split_traindata, args,\n","                              img_transforms=img_transforms)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","8400 samples in the train dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HHttphVCehCW","colab_type":"text"},"source":["LOAD DATASET FOR VALIDATION"]},{"cell_type":"code","metadata":{"id":"FKQgt_NDrA5L","colab_type":"code","outputId":"91f98c08-7f9c-4aff-e86b-fcf72543de78","executionInfo":{"status":"ok","timestamp":1561983145361,"user_tz":-120,"elapsed":2620,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["val_loader = get_dataloader(args.split_valdata, args,\n","                            img_transforms=val_transforms, split=\"val\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","2800 samples in the val dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zkN02QOHejlJ","colab_type":"text"},"source":["SPECIFY DEVICE"]},{"cell_type":"code","metadata":{"id":"NJU0i3PpLAHm","colab_type":"code","outputId":"234a405d-33be-4f8e-9eb1-2bba15af9d0b","executionInfo":{"status":"ok","timestamp":1561983148555,"user_tz":-120,"elapsed":601,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.cuda.is_available()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"X8NbSOen-wOy","colab_type":"code","colab":{}},"source":["# check for CUDA\n","if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NfyW9rMWerY1","colab_type":"text"},"source":["LOAD MODEL AND LOSS FUNCTION"]},{"cell_type":"code","metadata":{"id":"_cTc5vSct0U4","colab_type":"code","outputId":"e1a4567d-a857-4ca0-ac24-125f683bca15","executionInfo":{"status":"ok","timestamp":1561983166492,"user_tz":-120,"elapsed":14002,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["\n","model = SiameseCosine(pretrained=args.pretrained)\n","\n","model = model.to(device) # treure de train i validation\n","\n","loss_fn = RecognitionCriterion()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n","100%|██████████| 100441675/100441675 [00:04<00:00, 23235903.64it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"IDL9r6kseuZv","colab_type":"text"},"source":["SPECIFY WEIGHTS DIRECTORY"]},{"cell_type":"code","metadata":{"id":"ZFg3godAt06I","colab_type":"code","colab":{}},"source":["# directory where we'll store model weights\n","weights_dir = \"gdrive/My Drive/weights\"\n","if not osp.exists(weights_dir):\n","    os.mkdir(weights_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gcvYUiniexTw","colab_type":"text"},"source":["SPECIFY OPTIMIZER"]},{"cell_type":"code","metadata":{"id":"kRW8oa-H-3gT","colab_type":"code","colab":{}},"source":["#optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,\n","#                             weight_decay=args.weight_decay)\n","\n","optimizer = optim.SGD(model.parameters(), lr=args.lr,\n","                      momentum=args.momentum, weight_decay=args.weight_decay)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9r6ebJXezj-","colab_type":"text"},"source":["DEFINE CHECKPOINT"]},{"cell_type":"code","metadata":{"id":"WAS5FOei-8T1","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, filename=\"checkpoint.pth\", save_path=weights_dir):\n","    # check if the save directory exists\n","    if not Path(save_path).exists():\n","        Path(save_path).mkdir()\n","\n","    save_path = Path(save_path, filename)\n","    torch.save(state, str(save_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mmIwOBXke1bs","colab_type":"text"},"source":["RUN TRAIN"]},{"cell_type":"code","metadata":{"id":"E0ddySP2_DPR","colab_type":"code","outputId":"f1133089-756c-47d0-c880-bdb792817c6f","executionInfo":{"status":"ok","timestamp":1561998131954,"user_tz":-120,"elapsed":14943492,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","# train and evalute for `epochs`\n","loss_epoch_train = []\n","loss_epoch_val = []\n","acc_epoch_train = []\n","acc_epoch_val = []\n","\n","best_loss = 100\n","best_epoch = 0\n","\n","for epoch in range(args.start_epoch, args.epochs):\n","    # scheduler.step()\n","    train_loss = train(model, loss_fn, optimizer, train_loader, epoch, device=device)\n","    \n","    av_loss = np.mean(train_loss)\n","    loss_epoch_train.append(av_loss)\n","\n","\n","    val_loss = val(model, loss_fn, val_loader, epoch, device=device)\n","    \n","    av_loss = np.mean(val_loss)\n","    loss_epoch_val.append(av_loss)\n","\n","    if best_loss > av_loss:\n","        best_loss = av_loss\n","        best_epoch = epoch\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'batch_size': val_loader.batch_size,\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","         }, filename=str(args.resume)+\".pth\",\n","             save_path=weights_dir)\n","    \n","print(\"Best Epoch: \",best_epoch, \"Best Loss: \", best_loss)\n","    \n","epochs = range(1, len(loss_epoch_train) + 1)\n","# b is for \"solid blue line\"\n","plt.plot(epochs, loss_epoch_train, 'b', label='Training loss')\n","# r is for \"solid red line\"\n","plt.plot(epochs, loss_epoch_val, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","#epochs = range(1, len(acc_epoch_train) + 1)\n","# b is for \"solid blue line\"\n","#plt.plot(epochs, acc_epoch_train, 'b', label='Training accuracy')\n","# r is for \"solid red line\"\n","#plt.plot(epochs, acc_epoch_val, 'r', label='Validation accuracy')\n","#plt.title('Training and validation accuracy')\n","#plt.xlabel('Epochs')\n","#plt.ylabel('Accuracy')\n","#plt.legend()\n","#plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAIN Epoch [0]: [0/600]  Loss: [0.5610]\n","TRAIN Epoch [0]: [100/600]  Loss: [0.3774]\n","TRAIN Epoch [0]: [200/600]  Loss: [0.2685]\n","TRAIN Epoch [0]: [300/600]  Loss: [0.1456]\n","TRAIN Epoch [0]: [400/600]  Loss: [0.1728]\n","TRAIN Epoch [0]: [500/600]  Loss: [0.0885]\n","VAL Epoch [0]: [0/200]  Loss: [0.2157]\n","VAL Epoch [0]: [100/200]  Loss: [0.0393]\n","TRAIN Epoch [1]: [0/600]  Loss: [0.1673]\n","TRAIN Epoch [1]: [100/600]  Loss: [0.2162]\n","TRAIN Epoch [1]: [200/600]  Loss: [0.1609]\n","TRAIN Epoch [1]: [300/600]  Loss: [0.1529]\n","TRAIN Epoch [1]: [400/600]  Loss: [0.1068]\n","TRAIN Epoch [1]: [500/600]  Loss: [0.1165]\n","VAL Epoch [1]: [0/200]  Loss: [0.1952]\n","VAL Epoch [1]: [100/200]  Loss: [0.0481]\n","TRAIN Epoch [2]: [0/600]  Loss: [0.0874]\n","TRAIN Epoch [2]: [100/600]  Loss: [0.0387]\n","TRAIN Epoch [2]: [200/600]  Loss: [0.1039]\n","TRAIN Epoch [2]: [300/600]  Loss: [0.1351]\n","TRAIN Epoch [2]: [400/600]  Loss: [0.0957]\n","TRAIN Epoch [2]: [500/600]  Loss: [0.0793]\n","VAL Epoch [2]: [0/200]  Loss: [0.2242]\n","VAL Epoch [2]: [100/200]  Loss: [0.0453]\n","TRAIN Epoch [3]: [0/600]  Loss: [0.0811]\n","TRAIN Epoch [3]: [100/600]  Loss: [0.0476]\n","TRAIN Epoch [3]: [200/600]  Loss: [0.1077]\n","TRAIN Epoch [3]: [300/600]  Loss: [0.0902]\n","TRAIN Epoch [3]: [400/600]  Loss: [0.0475]\n","TRAIN Epoch [3]: [500/600]  Loss: [0.0765]\n","VAL Epoch [3]: [0/200]  Loss: [0.2140]\n","VAL Epoch [3]: [100/200]  Loss: [0.0451]\n","TRAIN Epoch [4]: [0/600]  Loss: [0.0344]\n","TRAIN Epoch [4]: [100/600]  Loss: [0.1302]\n","TRAIN Epoch [4]: [200/600]  Loss: [0.0727]\n","TRAIN Epoch [4]: [300/600]  Loss: [0.0854]\n","TRAIN Epoch [4]: [400/600]  Loss: [0.1118]\n","TRAIN Epoch [4]: [500/600]  Loss: [0.0825]\n","VAL Epoch [4]: [0/200]  Loss: [0.2158]\n","VAL Epoch [4]: [100/200]  Loss: [0.0416]\n","TRAIN Epoch [5]: [0/600]  Loss: [0.0857]\n","TRAIN Epoch [5]: [100/600]  Loss: [0.0396]\n","TRAIN Epoch [5]: [200/600]  Loss: [0.0844]\n","TRAIN Epoch [5]: [300/600]  Loss: [0.1076]\n","TRAIN Epoch [5]: [400/600]  Loss: [0.0553]\n","TRAIN Epoch [5]: [500/600]  Loss: [0.0489]\n","VAL Epoch [5]: [0/200]  Loss: [0.2075]\n","VAL Epoch [5]: [100/200]  Loss: [0.0462]\n","TRAIN Epoch [6]: [0/600]  Loss: [0.1269]\n","TRAIN Epoch [6]: [100/600]  Loss: [0.0526]\n","TRAIN Epoch [6]: [200/600]  Loss: [0.0903]\n","TRAIN Epoch [6]: [300/600]  Loss: [0.1039]\n","TRAIN Epoch [6]: [400/600]  Loss: [0.0244]\n","TRAIN Epoch [6]: [500/600]  Loss: [0.0900]\n","VAL Epoch [6]: [0/200]  Loss: [0.1986]\n","VAL Epoch [6]: [100/200]  Loss: [0.0340]\n","TRAIN Epoch [7]: [0/600]  Loss: [0.0514]\n","TRAIN Epoch [7]: [100/600]  Loss: [0.0370]\n","TRAIN Epoch [7]: [200/600]  Loss: [0.0614]\n","TRAIN Epoch [7]: [300/600]  Loss: [0.0697]\n","TRAIN Epoch [7]: [400/600]  Loss: [0.1060]\n","TRAIN Epoch [7]: [500/600]  Loss: [0.0726]\n","VAL Epoch [7]: [0/200]  Loss: [0.2170]\n","VAL Epoch [7]: [100/200]  Loss: [0.0185]\n","TRAIN Epoch [8]: [0/600]  Loss: [0.0473]\n","TRAIN Epoch [8]: [100/600]  Loss: [0.0599]\n","TRAIN Epoch [8]: [200/600]  Loss: [0.0712]\n","TRAIN Epoch [8]: [300/600]  Loss: [0.0998]\n","TRAIN Epoch [8]: [400/600]  Loss: [0.1062]\n","TRAIN Epoch [8]: [500/600]  Loss: [0.0631]\n","VAL Epoch [8]: [0/200]  Loss: [0.1996]\n","VAL Epoch [8]: [100/200]  Loss: [0.0245]\n","TRAIN Epoch [9]: [0/600]  Loss: [0.0329]\n","TRAIN Epoch [9]: [100/600]  Loss: [0.0582]\n","TRAIN Epoch [9]: [200/600]  Loss: [0.0332]\n","TRAIN Epoch [9]: [300/600]  Loss: [0.0449]\n","TRAIN Epoch [9]: [400/600]  Loss: [0.0845]\n","TRAIN Epoch [9]: [500/600]  Loss: [0.0570]\n","VAL Epoch [9]: [0/200]  Loss: [0.1975]\n","VAL Epoch [9]: [100/200]  Loss: [0.0379]\n","TRAIN Epoch [10]: [0/600]  Loss: [0.0933]\n","TRAIN Epoch [10]: [100/600]  Loss: [0.0652]\n","TRAIN Epoch [10]: [200/600]  Loss: [0.0818]\n","TRAIN Epoch [10]: [300/600]  Loss: [0.0354]\n","TRAIN Epoch [10]: [400/600]  Loss: [0.0869]\n","TRAIN Epoch [10]: [500/600]  Loss: [0.0290]\n","VAL Epoch [10]: [0/200]  Loss: [0.1687]\n","VAL Epoch [10]: [100/200]  Loss: [0.0475]\n","TRAIN Epoch [11]: [0/600]  Loss: [0.1043]\n","TRAIN Epoch [11]: [100/600]  Loss: [0.0657]\n","TRAIN Epoch [11]: [200/600]  Loss: [0.0675]\n","TRAIN Epoch [11]: [300/600]  Loss: [0.0398]\n","TRAIN Epoch [11]: [400/600]  Loss: [0.0330]\n","TRAIN Epoch [11]: [500/600]  Loss: [0.1272]\n","VAL Epoch [11]: [0/200]  Loss: [0.1753]\n","VAL Epoch [11]: [100/200]  Loss: [0.0339]\n","TRAIN Epoch [12]: [0/600]  Loss: [0.1134]\n","TRAIN Epoch [12]: [100/600]  Loss: [0.0319]\n","TRAIN Epoch [12]: [200/600]  Loss: [0.0815]\n","TRAIN Epoch [12]: [300/600]  Loss: [0.0122]\n","TRAIN Epoch [12]: [400/600]  Loss: [0.0666]\n","TRAIN Epoch [12]: [500/600]  Loss: [0.0647]\n","VAL Epoch [12]: [0/200]  Loss: [0.1855]\n","VAL Epoch [12]: [100/200]  Loss: [0.0530]\n","TRAIN Epoch [13]: [0/600]  Loss: [0.0716]\n","TRAIN Epoch [13]: [100/600]  Loss: [0.0588]\n","TRAIN Epoch [13]: [200/600]  Loss: [0.0708]\n","TRAIN Epoch [13]: [300/600]  Loss: [0.1318]\n","TRAIN Epoch [13]: [400/600]  Loss: [0.0461]\n","TRAIN Epoch [13]: [500/600]  Loss: [0.0326]\n","VAL Epoch [13]: [0/200]  Loss: [0.1812]\n","VAL Epoch [13]: [100/200]  Loss: [0.0472]\n","TRAIN Epoch [14]: [0/600]  Loss: [0.0345]\n","TRAIN Epoch [14]: [100/600]  Loss: [0.0790]\n","TRAIN Epoch [14]: [200/600]  Loss: [0.0679]\n","TRAIN Epoch [14]: [300/600]  Loss: [0.0682]\n","TRAIN Epoch [14]: [400/600]  Loss: [0.1288]\n","TRAIN Epoch [14]: [500/600]  Loss: [0.0219]\n","VAL Epoch [14]: [0/200]  Loss: [0.1688]\n","VAL Epoch [14]: [100/200]  Loss: [0.0370]\n","TRAIN Epoch [15]: [0/600]  Loss: [0.0157]\n","TRAIN Epoch [15]: [100/600]  Loss: [0.0407]\n","TRAIN Epoch [15]: [200/600]  Loss: [0.0244]\n","TRAIN Epoch [15]: [300/600]  Loss: [0.0212]\n","TRAIN Epoch [15]: [400/600]  Loss: [0.0625]\n","TRAIN Epoch [15]: [500/600]  Loss: [0.0557]\n","VAL Epoch [15]: [0/200]  Loss: [0.1910]\n","VAL Epoch [15]: [100/200]  Loss: [0.0418]\n","TRAIN Epoch [16]: [0/600]  Loss: [0.0603]\n","TRAIN Epoch [16]: [100/600]  Loss: [0.0733]\n","TRAIN Epoch [16]: [200/600]  Loss: [0.0864]\n","TRAIN Epoch [16]: [300/600]  Loss: [0.0315]\n","TRAIN Epoch [16]: [400/600]  Loss: [0.0350]\n","TRAIN Epoch [16]: [500/600]  Loss: [0.0143]\n","VAL Epoch [16]: [0/200]  Loss: [0.1524]\n","VAL Epoch [16]: [100/200]  Loss: [0.0337]\n","TRAIN Epoch [17]: [0/600]  Loss: [0.0589]\n","TRAIN Epoch [17]: [100/600]  Loss: [0.0270]\n","TRAIN Epoch [17]: [200/600]  Loss: [0.0612]\n","TRAIN Epoch [17]: [300/600]  Loss: [0.0495]\n","TRAIN Epoch [17]: [400/600]  Loss: [0.0681]\n","TRAIN Epoch [17]: [500/600]  Loss: [0.0254]\n","VAL Epoch [17]: [0/200]  Loss: [0.1643]\n","VAL Epoch [17]: [100/200]  Loss: [0.0468]\n","TRAIN Epoch [18]: [0/600]  Loss: [0.0493]\n","TRAIN Epoch [18]: [100/600]  Loss: [0.0082]\n","TRAIN Epoch [18]: [200/600]  Loss: [0.0799]\n","TRAIN Epoch [18]: [300/600]  Loss: [0.0993]\n","TRAIN Epoch [18]: [400/600]  Loss: [0.0640]\n","TRAIN Epoch [18]: [500/600]  Loss: [0.0185]\n","VAL Epoch [18]: [0/200]  Loss: [0.1920]\n","VAL Epoch [18]: [100/200]  Loss: [0.0335]\n","TRAIN Epoch [19]: [0/600]  Loss: [0.0065]\n","TRAIN Epoch [19]: [100/600]  Loss: [0.0319]\n","TRAIN Epoch [19]: [200/600]  Loss: [0.0862]\n","TRAIN Epoch [19]: [300/600]  Loss: [0.0430]\n","TRAIN Epoch [19]: [400/600]  Loss: [0.0442]\n","TRAIN Epoch [19]: [500/600]  Loss: [0.0399]\n","VAL Epoch [19]: [0/200]  Loss: [0.2004]\n","VAL Epoch [19]: [100/200]  Loss: [0.0444]\n","TRAIN Epoch [20]: [0/600]  Loss: [0.0624]\n","TRAIN Epoch [20]: [100/600]  Loss: [0.0886]\n","TRAIN Epoch [20]: [200/600]  Loss: [0.0696]\n","TRAIN Epoch [20]: [300/600]  Loss: [0.0178]\n","TRAIN Epoch [20]: [400/600]  Loss: [0.1080]\n","TRAIN Epoch [20]: [500/600]  Loss: [0.0523]\n","VAL Epoch [20]: [0/200]  Loss: [0.1583]\n","VAL Epoch [20]: [100/200]  Loss: [0.0486]\n","TRAIN Epoch [21]: [0/600]  Loss: [0.0583]\n","TRAIN Epoch [21]: [100/600]  Loss: [0.0278]\n","TRAIN Epoch [21]: [200/600]  Loss: [0.0579]\n","TRAIN Epoch [21]: [300/600]  Loss: [0.0926]\n","TRAIN Epoch [21]: [400/600]  Loss: [0.0575]\n","TRAIN Epoch [21]: [500/600]  Loss: [0.0344]\n","VAL Epoch [21]: [0/200]  Loss: [0.1785]\n","VAL Epoch [21]: [100/200]  Loss: [0.0298]\n","TRAIN Epoch [22]: [0/600]  Loss: [0.0366]\n","TRAIN Epoch [22]: [100/600]  Loss: [0.0454]\n","TRAIN Epoch [22]: [200/600]  Loss: [0.0697]\n","TRAIN Epoch [22]: [300/600]  Loss: [0.0661]\n","TRAIN Epoch [22]: [400/600]  Loss: [0.0582]\n","TRAIN Epoch [22]: [500/600]  Loss: [0.0463]\n","VAL Epoch [22]: [0/200]  Loss: [0.1735]\n","VAL Epoch [22]: [100/200]  Loss: [0.0399]\n","TRAIN Epoch [23]: [0/600]  Loss: [0.0634]\n","TRAIN Epoch [23]: [100/600]  Loss: [0.0656]\n","TRAIN Epoch [23]: [200/600]  Loss: [0.0544]\n","TRAIN Epoch [23]: [300/600]  Loss: [0.0220]\n","TRAIN Epoch [23]: [400/600]  Loss: [0.0873]\n","TRAIN Epoch [23]: [500/600]  Loss: [0.0386]\n","VAL Epoch [23]: [0/200]  Loss: [0.1900]\n","VAL Epoch [23]: [100/200]  Loss: [0.0379]\n","TRAIN Epoch [24]: [0/600]  Loss: [0.0546]\n","TRAIN Epoch [24]: [100/600]  Loss: [0.0577]\n","TRAIN Epoch [24]: [200/600]  Loss: [0.0257]\n","TRAIN Epoch [24]: [300/600]  Loss: [0.0541]\n","TRAIN Epoch [24]: [400/600]  Loss: [0.0551]\n","TRAIN Epoch [24]: [500/600]  Loss: [0.0436]\n","VAL Epoch [24]: [0/200]  Loss: [0.1829]\n","VAL Epoch [24]: [100/200]  Loss: [0.0503]\n","TRAIN Epoch [25]: [0/600]  Loss: [0.0511]\n","TRAIN Epoch [25]: [100/600]  Loss: [0.0215]\n","TRAIN Epoch [25]: [200/600]  Loss: [0.0389]\n","TRAIN Epoch [25]: [300/600]  Loss: [0.0584]\n","TRAIN Epoch [25]: [400/600]  Loss: [0.0513]\n","TRAIN Epoch [25]: [500/600]  Loss: [0.0245]\n","VAL Epoch [25]: [0/200]  Loss: [0.1788]\n","VAL Epoch [25]: [100/200]  Loss: [0.0555]\n","TRAIN Epoch [26]: [0/600]  Loss: [0.0090]\n","TRAIN Epoch [26]: [100/600]  Loss: [0.0713]\n","TRAIN Epoch [26]: [200/600]  Loss: [0.0194]\n","TRAIN Epoch [26]: [300/600]  Loss: [0.0469]\n","TRAIN Epoch [26]: [400/600]  Loss: [0.0470]\n","TRAIN Epoch [26]: [500/600]  Loss: [0.0394]\n","VAL Epoch [26]: [0/200]  Loss: [0.1971]\n","VAL Epoch [26]: [100/200]  Loss: [0.0311]\n","TRAIN Epoch [27]: [0/600]  Loss: [0.0313]\n","TRAIN Epoch [27]: [100/600]  Loss: [0.0203]\n","TRAIN Epoch [27]: [200/600]  Loss: [0.0911]\n","TRAIN Epoch [27]: [300/600]  Loss: [0.0435]\n","TRAIN Epoch [27]: [400/600]  Loss: [0.0478]\n","TRAIN Epoch [27]: [500/600]  Loss: [0.0494]\n","VAL Epoch [27]: [0/200]  Loss: [0.1670]\n","VAL Epoch [27]: [100/200]  Loss: [0.0365]\n","TRAIN Epoch [28]: [0/600]  Loss: [0.0863]\n","TRAIN Epoch [28]: [100/600]  Loss: [0.0387]\n","TRAIN Epoch [28]: [200/600]  Loss: [0.0408]\n","TRAIN Epoch [28]: [300/600]  Loss: [0.1099]\n","TRAIN Epoch [28]: [400/600]  Loss: [0.0129]\n","TRAIN Epoch [28]: [500/600]  Loss: [0.0216]\n","VAL Epoch [28]: [0/200]  Loss: [0.1689]\n","VAL Epoch [28]: [100/200]  Loss: [0.0523]\n","TRAIN Epoch [29]: [0/600]  Loss: [0.0330]\n","TRAIN Epoch [29]: [100/600]  Loss: [0.0171]\n","TRAIN Epoch [29]: [200/600]  Loss: [0.0213]\n","TRAIN Epoch [29]: [300/600]  Loss: [0.0186]\n","TRAIN Epoch [29]: [400/600]  Loss: [0.0243]\n","TRAIN Epoch [29]: [500/600]  Loss: [0.0134]\n","VAL Epoch [29]: [0/200]  Loss: [0.1645]\n","VAL Epoch [29]: [100/200]  Loss: [0.0454]\n","TRAIN Epoch [30]: [0/600]  Loss: [0.0392]\n","TRAIN Epoch [30]: [100/600]  Loss: [0.0709]\n","TRAIN Epoch [30]: [200/600]  Loss: [0.0374]\n","TRAIN Epoch [30]: [300/600]  Loss: [0.0574]\n","TRAIN Epoch [30]: [400/600]  Loss: [0.0110]\n","TRAIN Epoch [30]: [500/600]  Loss: [0.0855]\n","VAL Epoch [30]: [0/200]  Loss: [0.1339]\n","VAL Epoch [30]: [100/200]  Loss: [0.0388]\n","TRAIN Epoch [31]: [0/600]  Loss: [0.0652]\n","TRAIN Epoch [31]: [100/600]  Loss: [0.1076]\n","TRAIN Epoch [31]: [200/600]  Loss: [0.0572]\n","TRAIN Epoch [31]: [300/600]  Loss: [0.0428]\n","TRAIN Epoch [31]: [400/600]  Loss: [0.0812]\n","TRAIN Epoch [31]: [500/600]  Loss: [0.0444]\n","VAL Epoch [31]: [0/200]  Loss: [0.1546]\n","VAL Epoch [31]: [100/200]  Loss: [0.0513]\n","TRAIN Epoch [32]: [0/600]  Loss: [0.0413]\n","TRAIN Epoch [32]: [100/600]  Loss: [0.0200]\n","TRAIN Epoch [32]: [200/600]  Loss: [0.0047]\n","TRAIN Epoch [32]: [300/600]  Loss: [0.0502]\n","TRAIN Epoch [32]: [400/600]  Loss: [0.0255]\n","TRAIN Epoch [32]: [500/600]  Loss: [0.0593]\n","VAL Epoch [32]: [0/200]  Loss: [0.1672]\n","VAL Epoch [32]: [100/200]  Loss: [0.0302]\n","TRAIN Epoch [33]: [0/600]  Loss: [0.0309]\n","TRAIN Epoch [33]: [100/600]  Loss: [0.0105]\n","TRAIN Epoch [33]: [200/600]  Loss: [0.0624]\n","TRAIN Epoch [33]: [300/600]  Loss: [0.0189]\n","TRAIN Epoch [33]: [400/600]  Loss: [0.0356]\n","TRAIN Epoch [33]: [500/600]  Loss: [0.0251]\n","VAL Epoch [33]: [0/200]  Loss: [0.1404]\n","VAL Epoch [33]: [100/200]  Loss: [0.0314]\n","TRAIN Epoch [34]: [0/600]  Loss: [0.0807]\n","TRAIN Epoch [34]: [100/600]  Loss: [0.0082]\n","TRAIN Epoch [34]: [200/600]  Loss: [0.0255]\n","TRAIN Epoch [34]: [300/600]  Loss: [0.0515]\n","TRAIN Epoch [34]: [400/600]  Loss: [0.0182]\n","TRAIN Epoch [34]: [500/600]  Loss: [0.0119]\n","VAL Epoch [34]: [0/200]  Loss: [0.1557]\n","VAL Epoch [34]: [100/200]  Loss: [0.0420]\n","TRAIN Epoch [35]: [0/600]  Loss: [0.0407]\n","TRAIN Epoch [35]: [100/600]  Loss: [0.0108]\n","TRAIN Epoch [35]: [200/600]  Loss: [0.0253]\n","TRAIN Epoch [35]: [300/600]  Loss: [0.0221]\n","TRAIN Epoch [35]: [400/600]  Loss: [0.0707]\n","TRAIN Epoch [35]: [500/600]  Loss: [0.0598]\n","VAL Epoch [35]: [0/200]  Loss: [0.1531]\n","VAL Epoch [35]: [100/200]  Loss: [0.0505]\n","TRAIN Epoch [36]: [0/600]  Loss: [0.0269]\n","TRAIN Epoch [36]: [100/600]  Loss: [0.0584]\n","TRAIN Epoch [36]: [200/600]  Loss: [0.0209]\n","TRAIN Epoch [36]: [300/600]  Loss: [0.0498]\n","TRAIN Epoch [36]: [400/600]  Loss: [0.0195]\n","TRAIN Epoch [36]: [500/600]  Loss: [0.0089]\n","VAL Epoch [36]: [0/200]  Loss: [0.1617]\n","VAL Epoch [36]: [100/200]  Loss: [0.0323]\n","TRAIN Epoch [37]: [0/600]  Loss: [0.0393]\n","TRAIN Epoch [37]: [100/600]  Loss: [0.0299]\n","TRAIN Epoch [37]: [200/600]  Loss: [0.0443]\n","TRAIN Epoch [37]: [300/600]  Loss: [0.0399]\n","TRAIN Epoch [37]: [400/600]  Loss: [0.0625]\n","TRAIN Epoch [37]: [500/600]  Loss: [0.0107]\n","VAL Epoch [37]: [0/200]  Loss: [0.1586]\n","VAL Epoch [37]: [100/200]  Loss: [0.0424]\n","TRAIN Epoch [38]: [0/600]  Loss: [0.0145]\n","TRAIN Epoch [38]: [100/600]  Loss: [0.0213]\n","TRAIN Epoch [38]: [200/600]  Loss: [0.0388]\n","TRAIN Epoch [38]: [300/600]  Loss: [0.0660]\n","TRAIN Epoch [38]: [400/600]  Loss: [0.1199]\n","TRAIN Epoch [38]: [500/600]  Loss: [0.0178]\n","VAL Epoch [38]: [0/200]  Loss: [0.1611]\n","VAL Epoch [38]: [100/200]  Loss: [0.0389]\n","TRAIN Epoch [39]: [0/600]  Loss: [0.0209]\n","TRAIN Epoch [39]: [100/600]  Loss: [0.0100]\n","TRAIN Epoch [39]: [200/600]  Loss: [0.0172]\n","TRAIN Epoch [39]: [300/600]  Loss: [0.0203]\n","TRAIN Epoch [39]: [400/600]  Loss: [0.0318]\n","TRAIN Epoch [39]: [500/600]  Loss: [0.0378]\n","VAL Epoch [39]: [0/200]  Loss: [0.1436]\n","VAL Epoch [39]: [100/200]  Loss: [0.0414]\n","Best Epoch:  34 Best Loss:  0.10131235603475944\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaZI/h/dt5GUX6F2HwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"oJLPUCNKe4RA","colab_type":"text"},"source":["LOAD STORED WEIGHTS FOR THE BEST EPOCH"]},{"cell_type":"code","metadata":{"id":"XLhHSje0LRCb","colab_type":"code","outputId":"5661c9c3-ae0b-401e-b12b-986c35002566","executionInfo":{"status":"ok","timestamp":1562001415973,"user_tz":-120,"elapsed":694,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["weights = osp.join(weights_dir,args.resume+'.pth')\n","epoch = 35\n","if args.resume:\n","    print(weights)\n","    checkpoint = torch.load(weights)\n","    model.load_state_dict(checkpoint['model'])\n","    #optimizer.load_state_dict(checkpoint['optimizer'])\n","    # Set the start epoch if it has not been\n","    if not args.start_epoch:\n","        args.start_epoch = checkpoint['epoch']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gdrive/My Drive/weights/checkpoint_e63_40e_lr1e_3_SGD.pth\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Mk1MR5fe8wh","colab_type":"text"},"source":["COMPUTE SIMILARITIES AND PERCENTILS FOR THE VALIDATION SPLIT"]},{"cell_type":"code","metadata":{"id":"_BYWTUJCqpDa","colab_type":"code","outputId":"dc205fc3-fac2-4e92-9681-afc0fcdc8dab","executionInfo":{"status":"ok","timestamp":1562001463870,"user_tz":-120,"elapsed":43873,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["import numpy as np\n","# Compute similarities and obtain percentiles\n","\n","sim_pos, sim_neg = val_sim_lim(model, val_loader, epoch, device=device)\n","pos_95 = np.percentile(sim_pos,95)\n","pos_5 = np.percentile(sim_pos,5)\n","pos_max = np.amax(sim_pos)\n","pos_min = np.amin(sim_pos)\n","print(pos_95, pos_5, pos_max, pos_min)\n","\n","neg_95 = np.percentile(sim_neg,95)\n","neg_5 = np.percentile(sim_neg,5)\n","neg_max = np.amax(sim_neg)\n","neg_min = np.amin(sim_neg)\n","print(neg_95, neg_5, neg_max, neg_min)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["VAL Epoch [35]: [0/200] \n","VAL Epoch [35]: [100/200] \n","0.9945800691843033 0.5866807132959366 0.9982953667640686 -0.5039698481559753\n","0.9588154762983322 -0.5867477089166642 0.9975836873054504 -0.8150036931037903\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lnQc6zJpfCwb","colab_type":"text"},"source":["SELECT THRESHOLD"]},{"cell_type":"code","metadata":{"id":"1C7gxkZdyXnV","colab_type":"code","outputId":"3068a3ac-56bc-4d88-a1b8-5dc6a4b75d27","executionInfo":{"status":"ok","timestamp":1562002708092,"user_tz":-120,"elapsed":1073476,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":990}},"source":["import numpy\n","\n","# Select treshold\n","best_acc = 0\n","best_tr = 0\n","sup = numpy.round(neg_95,decimals=3)\n","inf = numpy.round(pos_5,decimals=3)\n","for value in numpy.arange(inf, sup, 0.1):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","\n","sup = numpy.round(best_tr+.05,decimals=3)\n","inf = numpy.round(best_tr-.05,decimals=3)\n","for value in numpy.arange(inf, sup, 0.01):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","\n","sup = numpy.round(best_tr+.005,decimals=3)\n","inf = numpy.round(best_tr-.005,decimals=3)\n","for value in numpy.arange(inf, sup, 0.001):\n","    numpy.round(value,decimals=3)\n","    val_acc = val_tr(model, val_loader, epoch, device=device, tr=value)\n","    av_acc = np.mean(val_acc)\n","    if av_acc > best_acc:\n","      best_acc = av_acc\n","      best_tr = value\n","      print('Best accuracy:', av_acc, 'Treshold:', best_tr)\n","      \n","print('Best accuracy:', av_acc, 'Treshold:', best_tr)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["VAL Epoch [35]: [0/200]  Accuracy: [0.5714285714285714]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","Best accuracy: 0.8382142857142857 Treshold: 0.587\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.8435714285714286 Treshold: 0.6869999999999999\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.7857142857142857]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.5714285714285714]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","Best accuracy: 0.8446428571428573 Treshold: 0.657\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","Best accuracy: 0.845 Treshold: 0.667\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","Best accuracy: 0.8453571428571429 Treshold: 0.668\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","VAL Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","VAL Epoch [35]: [100/200]  Accuracy: [0.9285714285714286]\n","Best accuracy: 0.8453571428571428 Treshold: 0.668\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HM2vt5PafFvf","colab_type":"text"},"source":["LOAD DATASET SPLIT FOR TEST"]},{"cell_type":"code","metadata":{"id":"TRHfMSYutwAS","colab_type":"code","outputId":"58255f51-902f-457a-98b1-d03a2258022f","executionInfo":{"status":"ok","timestamp":1562003456605,"user_tz":-120,"elapsed":3733,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["test_loader = get_dataloader(args.split_testdata, args,\n","                             img_transforms=val_transforms, split=\"test\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset loaded\n","2800 samples in the test dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uZxEaUJtfIPh","colab_type":"text"},"source":["RUN TEST"]},{"cell_type":"code","metadata":{"id":"EYZn9qBIuQ4O","colab_type":"code","outputId":"ef55a369-5a35-4c2b-e71d-3b89b9d351d7","executionInfo":{"status":"ok","timestamp":1562003544091,"user_tz":-120,"elapsed":80117,"user":{"displayName":"Billing Department","photoUrl":"","userId":"18156600915960294960"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Test\n","\n","best_tr = 0.668\n","test_acc = test(model, loss_fn, test_loader, epoch, device=device, tr=best_tr)\n","av_acc = np.mean(test_acc)\n","print('Average test accuracy:', av_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TEST Epoch [35]: [0/200]  Accuracy: [0.6428571428571429]\n","TEST Epoch [35]: [100/200]  Accuracy: [0.8571428571428571]\n","Average test accuracy: 0.8589285714285714\n"],"name":"stdout"}]}]}